{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13644596,"sourceType":"datasetVersion","datasetId":8673648}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[{"file_id":"1s0Cped5MHj8Lnef6mijNTjLULzbwdDRE","timestamp":1762620994425},{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/christophbieritz/ppo-stable-baseline-v2.e0d09903-048c-4ed6-b4b2-0352c7265933.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20251108/auto/storage/goog4_request&X-Goog-Date=20251108T060700Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=651bd69ccf890d4aef35ff5f0ed5871631ce648bcadfcd5bfeb3367cf72adf30fffbf3451176c7bc7c23603a2477953ab955d70842f359b891dc50c6f2d9174d578b4c53c0af0c2506d49e830fa3ec5141a2bcd6ed6c72faf1768ad5f10745b2556b303c5f15f80334e18555812e70a5f44cdc3cfb4a284d8380daf3ef38a1884a819b1fe031b4b2209aeccc1d0ee02265eb332a1241d9a9b5564560fd12ed3159f0e7b1181a903c8bebc16062b41e85b67e61b926e73d8e426700c723d319965d53778182a6f215f6a259dde0ddc642cd43358577b99040cf5dbc0c08f175f4d2d004df045cf21ca8fb4705a4e266ef0dda5c42ddbf613a2fb4a62d46714e29","timestamp":1762582068257}]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# 1. Installationen\n","# ----------------------------------------------------------------------\n","!pip install numpy pandas torch\n","!pip install gymnasium stable-baselines3 wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ChdipO5KQ50","executionInfo":{"status":"ok","timestamp":1763288973764,"user_tz":-60,"elapsed":25094,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}},"outputId":"c80f8371-0d50-4224-b883-d36b09ed06fc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Collecting stable-baselines3\n","  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.8.0+cu126)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n","Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n","Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: stable-baselines3\n","Successfully installed stable-baselines3-2.7.0\n"]}]},{"cell_type":"code","source":["# 2. Standard- & ML-Bibliotheken (Alle Imports)\n","# ----------------------------------------------------------------------\n","import os\n","import uuid # Für eindeutige Run-Namen\n","from functools import partial # Für parallele Umgebungen\n","from typing import List, Dict, Optional, Callable\n","\n","# Daten & ML\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.distributions import Dirichlet\n","\n","# Gymnasium (OpenAI Gym Ersatz)\n","import gymnasium as gym\n","from gymnasium import spaces\n","\n","# Stable Baselines 3 (SB3)\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.policies import ActorCriticPolicy\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n","from stable_baselines3.common.monitor import Monitor\n","from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n","from stable_baselines3.common.distributions import Distribution\n","from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n","\n","# Weights & Biases (W&B)\n","import wandb\n","from wandb.integration.sb3 import WandbCallback\n","\n","# Google Colab (falls Umgebung 'colab' ist)\n","try:\n","    from google.colab import drive, userdata\n","except ImportError:\n","    print(\"Nicht in Colab-Umgebung. Überspringe Colab-Imports.\")"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T06:04:21.18345Z","iopub.execute_input":"2025-11-08T06:04:21.183657Z","iopub.status.idle":"2025-11-08T06:04:43.41714Z","shell.execute_reply.started":"2025-11-08T06:04:21.183637Z","shell.execute_reply":"2025-11-08T06:04:43.416329Z"},"id":"usf9fHh4E1FC","executionInfo":{"status":"ok","timestamp":1763289018759,"user_tz":-60,"elapsed":44991,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4c0e773-ae8a-43fd-e720-357641c640b0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n","Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n","See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}],"execution_count":2},{"cell_type":"code","source":["# %% [code]\n","#\n","# 3. KONFIGURATION, PORTABILITÄT & SETUP\n","# (ANGEPASST MIT WANDB-LOGGING-PFAD)\n","# ----------------------------------------------------------------------\n","\n","# --- 1. Umgebungs-Erkennung & Secrets ---\n","ENV = \"colab\"\n","WANDB_API_KEY = \"\"\n","BASE_DIR = \"\"\n","\n","if ENV == \"colab\":\n","    try:\n","        drive.mount('/content/drive')\n","        WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n","        BASE_DIR = '/content/drive/MyDrive/01_Data/projects/PPO_portfolio_optimization'\n","        print(\"Umgebung: Google Colab. Drive gemountet.\")\n","    except Exception as e:\n","        print(f\"Colab-Fehler: {e}\")\n","else:\n","    print(f\"Umgebung: {ENV} (Lokale Pfade evtl. anpassen)\")\n","\n","# W&B Login\n","if WANDB_API_KEY:\n","    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n","    wandb.login(key=WANDB_API_KEY)\n","else:\n","    print(\"WARNUNG: WANDB_API_KEY nicht gefunden.\")\n","\n","# --- 2. Dynamischer Notebook-Name für W&B ---\n","NOTEBOOK_NAME = \"PPO_Training_V3_CSV_Input.ipynb\"\n","os.environ['WANDB_NOTEBOOK_NAME'] = NOTEBOOK_NAME\n","print(f\"Notebook-Name für W&B gesetzt: {NOTEBOOK_NAME}\")\n","\n","# --- 3. Zentrale Konfiguration (Config-Objekt) ---\n","config = {\n","    \"project_name\": \"PPO_Portfolio_SP500\",\n","    \"run_name\": f\"PPO_LSTM_CSV_{uuid.uuid4().hex[:8]}\",\n","    \"use_wandb\": True,\n","    \"save_model\": True,\n","    \"env_id\": ENV,\n","\n","    \"feature_csv_path\": os.path.join(BASE_DIR, 'processed_data', 'features_cleaned.csv'),\n","    \"toy_data_csv_path\": None,\n","    \"model_save_dir\": os.path.join(BASE_DIR, 'models'),\n","\n","    # [NEU] W&B Log-Verzeichnis im Google Drive\n","    \"wandb_log_dir\": os.path.join(BASE_DIR, 'data', 'wandb_logs'),\n","\n","    \"train_start_date\": '2005-01-01',\n","    \"train_end_date\": '2019-12-31',\n","    \"eval_start_date\": '2020-01-01',\n","    \"eval_end_date\": '2024-12-31',\n","\n","    \"initial_balance\": 10000.0,\n","    \"window_size\": 30,\n","    \"transaction_cost_pct\": 0.001,\n","\n","    \"total_timesteps\": 5_000_000,\n","    \"num_cpu_cores\": 4,\n","\n","    \"n_steps\": 4096,\n","    \"batch_size\": 1024,\n","    \"n_epochs\": 8,\n","    \"learning_rate\": 0.0001,\n","    \"gamma\": 0.99,\n","    \"gae_lambda\": 0.95,\n","    \"clip_range\": 0.1,\n","    \"vf_coef\": 0.5,\n","    \"ent_coef\": 0.0,\n","\n","    \"extractor_type\": \"LSTM\",\n","    \"extractor_hidden_size\": 128,\n","    \"policy_pi_arch\": [64],\n","    \"policy_vf_arch\": [64]\n","}\n","\n","os.makedirs(config['model_save_dir'], exist_ok=True)\n","os.makedirs(config['wandb_log_dir'], exist_ok=True) # [NEU] Erstelle das Log-Verzeichnis\n","\n","print(f\"--- Konfiguration geladen für: {ENV} ---\")\n","print(f\"Datenquelle (CSV): {config['feature_csv_path']}\")\n","print(f\"W&B Logs werden gespeichert in: {config['wandb_log_dir']}\")"],"metadata":{"id":"sm9NjcNZpfTg","executionInfo":{"status":"ok","timestamp":1763289057381,"user_tz":-60,"elapsed":38621,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b80f8b7-3dbb-462f-91af-8a36be5c55e4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab-Fehler: Error: credential propagation was unsuccessful\n","WARNUNG: WANDB_API_KEY nicht gefunden.\n","Notebook-Name für W&B gesetzt: PPO_Training_V3_CSV_Input.ipynb\n","--- Konfiguration geladen für: colab ---\n","Datenquelle (CSV): processed_data/features_cleaned.csv\n","W&B Logs werden gespeichert in: data/wandb_logs\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import gymnasium as gym\n","from gymnasium import spaces\n","\n","class PortfolioEnv(gym.Env):\n","    \"\"\"\n","    Custom Environment für Portfolio-Optimierung (basierend auf Stable_Baseline_V4).\n","    - Observation Space: Dict (Features [LSTM Input], Portfolio Weights [MLP Input])\n","    - Action Space: Box (Logits für eine Dirichlet-Verteilung)\n","    - Reward: Log-Return des Portfolios.\n","    - Termination: Max Drawdown oder Bankrott.\n","    \"\"\"\n","    metadata = {'render_modes': ['human'], 'render_fps': 30}\n","\n","    def __init__(self, data_df: pd.DataFrame, **kwargs):\n","        super(PortfolioEnv, self).__init__()\n","\n","        self.data = data_df\n","        # Price Ratios sind exp(Log Returns).\n","        self.price_ratios = np.exp(data_df.loc[:, 'LogReturns'].values)\n","\n","        # Konfiguration\n","        self.initial_capital = kwargs.get(\"initial_capital\", 10000.0)\n","        self.max_drawdown = kwargs.get(\"max_drawdown\", 0.5)\n","        self.transaction_cost_pct = kwargs.get(\"transaction_cost_pct\", 0.001)\n","        self.lookback_window = kwargs.get(\"lookback_window\", 10)\n","        self.bankrupt_threshold = kwargs.get(\"bankrupt_threshold\", 1.0) # Neuer Parameter für Stabilität\n","\n","        # Dimensionen\n","        self.num_assets = self.price_ratios.shape[1]\n","        self.num_features = self.data.columns.get_level_values(0).nunique()\n","        self.N_ASSETS_PLUS_CASH = self.num_assets + 1 # Cash ist Index 0\n","\n","        # State\n","        self.current_step = self.lookback_window # Start nach Lookback-Window\n","        self.max_steps = len(data_df) - 1\n","        self.current_portfolio_value = self.initial_capital\n","        self.peak_portfolio_value = self.initial_capital\n","\n","        # Initialisierung der Gewichte (Cash = 100%)\n","        self.current_weights = np.zeros(self.N_ASSETS_PLUS_CASH, dtype=np.float32)\n","        self.current_weights[0] = 1.0\n","\n","        # Action Space (Logits, die zu Alphas werden)\n","        # SB3 benötigt finite Grenzen, daher [-100, 100] statt [-inf, inf]\n","        self.action_space = spaces.Box(low=-100.0, high=100.0, shape=(self.N_ASSETS_PLUS_CASH,), dtype=np.float32)\n","\n","\n","        # Observation Space (Input für Actor-Critic Netzwerke)\n","        self.observation_space = spaces.Dict({\n","            # Features (L, N_Assets, N_Features) -> LSTM-Input\n","            'features': spaces.Box(low=-np.inf, high=np.inf,\n","                                   shape=(self.lookback_window, self.num_assets, self.num_features),\n","                                   dtype=np.float32),\n","            # Portfolio Weights (N_Assets + Cash) -> MLP-Input\n","            'portfolio_weights': spaces.Box(low=0.0, high=1.0,\n","                                            shape=(self.N_ASSETS_PLUS_CASH,),\n","                                            dtype=np.float32)\n","        })\n","\n","        # --- Daten-Validierung (Price Ratios) ---\n","        max_ratio = np.max(self.price_ratios)\n","        min_ratio = np.min(self.price_ratios)\n","        if np.isinf(max_ratio) or np.isinf(min_ratio) or np.isnan(max_ratio) or np.isnan(min_ratio):\n","             print(\"\\n\" + \"=\"*70)\n","             print(f\"FATALER FEHLER: 'inf' oder 'NaN' in price_ratios gefunden.\")\n","             print(f\"Max: {max_ratio}, Min: {min_ratio}\")\n","             print(\"Bitte Notebook 02 ausführen und LogReturns clippen!\")\n","             print(\"=\"*70 + \"\\n\")\n","             raise ValueError(\"inf/nan in price_ratios\")\n","\n","        print(\"--- Daten-Validierung (Price Ratios) ---\")\n","        print(f\"Max Price Ratio: {max_ratio}\")\n","        print(f\"Min Price Ratio: {min_ratio}\")\n","        print(f\"Mean Price Ratio: {np.mean(self.price_ratios)}\")\n","        print(f\"NaNs in Price Ratios: {np.isnan(self.price_ratios).sum()}\")\n","        print(\"------------------------------------------\")\n","\n","\n","    def _get_obs(self):\n","        # Erstellt den Observationsvektor für den aktuellen Schritt\n","        start = self.current_step - self.lookback_window\n","        end = self.current_step\n","\n","        # Extrahieren und Reshape der Feature-History für die letzten L Tage\n","        feature_history_df = self.data.iloc[start:end]\n","\n","        # (L, N_Features, N_Assets) -> (L, N_Assets, N_Features)\n","        feature_history = feature_history_df.values.reshape(\n","            self.lookback_window, self.num_features, self.num_assets\n","        ).swapaxes(1, 2)\n","\n","        return {\n","            'features': feature_history.astype(np.float32),\n","            'portfolio_weights': self.current_weights.astype(np.float32)\n","        }\n","\n","\n","    def step(self, action: np.ndarray):\n","\n","        # ##################################################################\n","        # ### HIER IST DIE ÄNDERUNG: Softmax -> Dirichlet ###\n","        # ##################################################################\n","        #\n","        # ALT (Softmax):\n","        # max_logit = np.max(action)\n","        # exp_logits = np.exp(action - max_logit)\n","        # new_weights = exp_logits / np.sum(exp_logits)\n","        #\n","        # NEU (Dirichlet):\n","        # 1. Wandle Agenten-Ausgabe (Logits) in Alphas > 0 um\n","        #    Wir nutzen softplus + epsilon (1e-6) für numerische Stabilität\n","        alpha = np.log(1.0 + np.exp(action)) + 1e-6\n","\n","        # 2. Die Gewichte sind der Erwartungswert der Verteilung\n","        #    E[w_i] = alpha_i / sum(alpha_j)\n","        new_weights = alpha / np.sum(alpha)\n","        # ##################################################################\n","\n","\n","        # 2. Portfolio-Wertentwicklung berechnen\n","        asset_ratios_today = self.price_ratios[self.current_step]\n","\n","        # KONVENTION: Cash ist Index 0\n","        price_ratios_with_cash = np.insert(asset_ratios_today, 0, 1.0) # [1.0, R_1, R_2, ...]\n","\n","        # Portfolio-Return = (Summe(Gewicht * Ratio))\n","        portfolio_return_before_costs = np.dot(new_weights, price_ratios_with_cash)\n","\n","        # 3. Transaktionskosten berechnen\n","\n","        # Kostenberechnung (ignoriert Index 0, Cash)\n","        turnover = np.sum(np.abs(new_weights[1:] - self.current_weights[1:]))\n","        cost = turnover * self.transaction_cost_pct\n","\n","        # 4. Finaler Return und neuer Portfolio-Wert\n","        portfolio_return_after_costs = portfolio_return_before_costs - cost\n","\n","        # Sicherstellen, dass der Return nicht negativ ist (Verlust > 100% ist nicht möglich)\n","        portfolio_return_after_costs = max(portfolio_return_after_costs, 0)\n","\n","        prev_portfolio_value = self.current_portfolio_value\n","        self.current_portfolio_value *= portfolio_return_after_costs\n","\n","        # 5. Reward (Log-Return)\n","        # Stabilitäts-Epsilon (1e-10) für den Logarithmus\n","        reward = np.log(max(portfolio_return_after_costs, 1e-10))\n","\n","        # 6. Metriken und State-Update\n","        self.current_step += 1\n","        self.current_weights = new_weights\n","\n","        # Drawdown-Berechnung\n","        self.peak_portfolio_value = max(self.peak_portfolio_value, self.current_portfolio_value)\n","        current_drawdown = (self.peak_portfolio_value - self.current_portfolio_value) / self.peak_portfolio_value\n","\n","        # 7. Termination und Truncation\n","        terminated = False\n","        truncated = False\n","\n","        # Termination 1: Ende der Daten\n","        if self.current_step >= self.max_steps:\n","            terminated = True\n","\n","        # Termination 2: Max Drawdown überschritten\n","        if current_drawdown > self.max_drawdown:\n","            terminated = True\n","            reward = -10.0 # Harte Strafe für Drawdown-Verletzung\n","\n","        # Termination 3: Bankrott (Portfolio-Wert ist quasi Null)\n","        if self.current_portfolio_value < self.bankrupt_threshold:\n","            terminated = True\n","            reward = -20.0 # Sehr harte Strafe für Bankrott\n","            self.current_portfolio_Value = 0.0 # Auf Null setzen\n","\n","        # Info-Dict für Logging (W&B)\n","        info = {\n","            # Alle NumPy-Typen explizit in Standard-Python-Typen umwandeln\n","            'portfolio_value': float(self.current_portfolio_value),\n","            'prev_portfolio_value': float(prev_portfolio_value),\n","            'portfolio_value_after_costs': float(portfolio_return_after_costs), # KORRIGIERT\n","            'reward': float(reward),\n","            'transaction_costs': float(cost * prev_portfolio_value), # Absolute Kosten\n","            'turnover': float(turnover),\n","            'is_bankrupt': bool(self.current_portfolio_value < self.bankrupt_threshold)\n","        }\n","\n","        # (Die Logging-Schleife für Gewichte bleibt auskommentiert,\n","        # um die SB3-Standardmetriken nicht zu überfluten)\n","        for i, w in enumerate(self.current_weights):\n","             info[f'weight_{i}'] = float(w)\n","\n","        return self._get_obs(), reward, terminated, truncated, info\n","\n","\n","    def reset(self, seed=None, options=None):\n","        super().reset(seed=seed)\n","\n","        self.current_step = self.lookback_window\n","        self.current_portfolio_value = self.initial_capital\n","        self.peak_portfolio_value = self.initial_capital\n","\n","        # Start mit 100% Cash\n","        self.current_weights = np.zeros(self.N_ASSETS_PLUS_CASH, dtype=np.float32)\n","        self.current_weights[0] = 1.0\n","\n","        return self._get_obs(), {}\n","\n","    def render(self):\n","        pass # Nicht benötigt für Colab-Training\n","\n","    def close(self):\n","        pass"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T06:04:46.161665Z","iopub.execute_input":"2025-11-08T06:04:46.162019Z","iopub.status.idle":"2025-11-08T06:04:46.184992Z","shell.execute_reply.started":"2025-11-08T06:04:46.161995Z","shell.execute_reply":"2025-11-08T06:04:46.184391Z"},"id":"GvvxJD8DE1FE","executionInfo":{"status":"ok","timestamp":1763289057428,"user_tz":-60,"elapsed":8,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}}},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# 5. Angepasster Feature Extractor (Dynamische Architektur)\n","# ----------------------------------------------------------------------\n","class CustomCombinedExtractor(BaseFeaturesExtractor):\n","    def __init__(\n","        self,\n","        observation_space: spaces.Dict,\n","\n","        # Diese Argumente kommen direkt aus policy_kwargs\n","        extractor_type: str = \"LSTM\",\n","        hidden_size: int = 64\n","    ):\n","\n","        # --- Dimensionen bestimmen ---\n","        market_space = observation_space[\"features\"] # [FIX] Changed 'market_data' to 'features'\n","        weights_space = observation_space[\"portfolio_weights\"]\n","        window_size, num_assets, num_features = market_space.shape\n","\n","        self.lstm_input_size = num_assets * num_features\n","        self.lstm_hidden_size = hidden_size\n","\n","        features_dim = self.lstm_hidden_size + weights_space.shape[0]\n","\n","        # super().__init__ MUSS hier aufgerufen werden\n","        super().__init__(observation_space, features_dim)\n","\n","        # --- Netzwerk definieren (basierend auf den direkten Argumenten) ---\n","\n","        if extractor_type.upper() == \"LSTM\":\n","            self.rnn = nn.LSTM(\n","                input_size=self.lstm_input_size,\n","                hidden_size=self.lstm_hidden_size,\n","                batch_first=True\n","            )\n","        elif extractor_type.upper() == \"GRU\":\n","            self.rnn = nn.GRU(\n","                input_size=self.lstm_input_size,\n","                hidden_size=self.lstm_hidden_size,\n","                batch_first=True\n","            )\n","        # --- ENDE KORREKTUR v4 ---\n","        else:\n","            raise ValueError(f\"Unbekannter extractor_type: {extractor_type}\")\n","\n","        print(f\"CustomCombinedExtractor (Typ: {extractor_type}, Hidden: {hidden_size}) initialisiert.\")\n","\n","\n","    def forward(self, observations: dict) -> torch.Tensor:\n","        market_data = observations[\"features\"] # [FIX] Changed 'market_data' to 'features'\n","        portfolio_weights = observations[\"portfolio_weights\"]\n","        batch_size, window_size = market_data.shape[0], market_data.shape[1]\n","\n","        flat_market_data = market_data.reshape(batch_size, window_size, -1)\n","\n","        rnn_out, hidden = self.rnn(flat_market_data)\n","\n","        if isinstance(hidden, tuple): # LSTM\n","            last_hidden_state = hidden[0][-1]\n","        else: # GRU\n","            last_hidden_state = hidden[-1]\n","\n","        combined_features = torch.cat([last_hidden_state, portfolio_weights], dim=1)\n","        return combined_features\n","\n","print(\"--- CustomCombinedExtractor Klasse (KORRIGIERT v4) definiert ---\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T06:04:46.185743Z","iopub.execute_input":"2025-11-08T06:04:46.186072Z","iopub.status.idle":"2025-11-08T06:04:46.204941Z","shell.execute_reply.started":"2025-11-08T06:04:46.186054Z","shell.execute_reply":"2025-11-08T06:04:46.204406Z"},"id":"CX7qW-QLE1FF","executionInfo":{"status":"ok","timestamp":1763289057445,"user_tz":-60,"elapsed":16,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fa678bb-0047-4435-e017-46f4e7b03508"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- CustomCombinedExtractor Klasse (KORRIGIERT v4) definiert ---\n"]}],"execution_count":5},{"cell_type":"code","source":["# %% [code]\n","#\n","# 6. POLICY-KLASSEN & DER \"UNIFIED CALLBACK\"\n","# (ERSETZT ALLE ALTEN CALLBACKS - MIT BUGFIX V2)\n","# ----------------------------------------------------------------------\n","import pandas as pd\n","from stable_baselines3.common.callbacks import BaseCallback\n","\n","# --- Policy-Klassen (unverändert) ---\n","\n","class CustomDirichletDistribution(Distribution):\n","    def __init__(self, action_dim: int):\n","        super().__init__()\n","        self.action_dim = action_dim\n","    def proba_distribution_net(self, latent_dim: int) -> nn.Module:\n","        action_net = nn.Linear(latent_dim, self.action_dim)\n","        return action_net\n","    def proba_distribution(self, action_net_output: torch.Tensor) -> \"CustomDirichletDistribution\":\n","        alphas = torch.nn.functional.softplus(action_net_output) + 1.0\n","        self.distribution = Dirichlet(alphas)\n","        return self\n","    def log_prob(self, actions: torch.Tensor) -> torch.Tensor:\n","        actions_clipped = torch.clamp(actions, 1e-6, 1.0 - 1e-6)\n","        actions_normalized = actions_clipped / torch.sum(actions_clipped, dim=-1, keepdim=True)\n","        return self.distribution.log_prob(actions_normalized)\n","    def entropy(self) -> torch.Tensor:\n","        return self.distribution.entropy()\n","    def sample(self) -> torch.Tensor:\n","        return self.distribution.rsample()\n","    def mode(self) -> torch.Tensor:\n","        return self.distribution.mean\n","    def actions_from_params(self, action_net_output: torch.Tensor, deterministic: bool = False) -> torch.Tensor:\n","        self.proba_distribution(action_net_output)\n","        if deterministic: return self.mode()\n","        return self.sample()\n","    def log_prob_from_params(self, action_net_output: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n","        self.proba_distribution(action_net_output)\n","        actions = self.sample()\n","        log_prob = self.log_prob(actions)\n","        return actions, log_prob\n","\n","class CustomActorCriticPolicy(ActorCriticPolicy):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","    def _get_action_dist_from_space(self, action_space: spaces.Box) -> CustomDirichletDistribution:\n","        if not isinstance(action_space, spaces.Box):\n","            raise ValueError(\"DirichletPolicy unterstützt nur Box Action Space.\")\n","        action_dim = action_space.shape[0]\n","        return CustomDirichletDistribution(action_dim)\n","\n","\n","# --- [KORRIGIERT] Der \"Unified Observability Callback\" ---\n","\n","class UnifiedObservabilityCallback(BaseCallback):\n","    \"\"\"\n","    (Version 2 - Behebt den Absturz beim Mischen von Info-Dicts)\n","    \"\"\"\n","    def __init__(self, eval_env_fn: Callable, eval_freq: int, log_path: str, verbose=0):\n","        super(UnifiedObservabilityCallback, self).__init__(verbose)\n","\n","        self.eval_env_fn = eval_env_fn\n","        self.eval_freq = eval_freq\n","        self.log_path = log_path\n","        self.best_mean_reward = -np.inf\n","\n","        # [KORREKTUR] Wir trennen die Datenspeicher\n","        self.rollout_step_infos = [] # Für 'is_bankrupt', 'turnover' etc.\n","        self.rollout_episode_infos = [] # Nur für {'r': ..., 'l': ...}\n","\n","    def _init_callback(self):\n","        self.eval_env = DummyVecEnv([self.eval_env_fn])\n","\n","    def _on_step(self) -> bool:\n","        \"\"\" 1. Sammelt 'info'-Dicts bei JEDEM Schritt (getrennt) \"\"\"\n","        for info in self.locals.get('infos', []):\n","            # 'episode' wird vom Monitor-Wrapper hinzugefügt, wenn eine Episode endet\n","            if 'episode' in info.keys():\n","                self.rollout_episode_infos.append(info['episode'])\n","\n","            # 'portfolio_value' kommt von unserer Env bei JEDEM Schritt\n","            if \"portfolio_value\" in info.keys():\n","                self.rollout_step_infos.append(info)\n","        return True\n","\n","    def _on_rollout_end(self) -> None:\n","        \"\"\" Wird am Ende jedes Rollouts aufgerufen. \"\"\"\n","\n","        # --- 2. Loggt ROLLOUT-Aggregate (Live-Metriken) ---\n","        self._log_rollout_aggregates()\n","\n","        # --- 3. Prüft, ob es Zeit für die EVAL-Runde ist ---\n","        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n","            self._run_evaluation_and_log_table()\n","\n","    def _log_rollout_aggregates(self):\n","        \"\"\" Berechnet und loggt Aggregate (jetzt mit getrennten DFs) \"\"\"\n","        if self.verbose > 0:\n","            print(f\"\\n--- [Callback] Logge Rollout-Aggregate (Schritt: {self.num_timesteps}) ---\")\n","\n","        # --- Logge Episoden-Metriken ---\n","        if self.rollout_episode_infos:\n","            df_episodes = pd.DataFrame(self.rollout_episode_infos)\n","            self.logger.record(\"rollout/ep_reward_mean\", df_episodes['r'].mean())\n","            self.logger.record(\"rollout/ep_len_mean\", df_episodes['l'].mean())\n","\n","        # --- Logge Live-Schritt-Metriken ---\n","        if self.rollout_step_infos:\n","            df_steps = pd.DataFrame(self.rollout_step_infos)\n","            self.logger.record(\"live/bankrupt_rate\", df_steps['is_bankrupt'].mean())\n","            self.logger.record(\"live/avg_turnover\", df_steps['turnover'].mean())\n","            self.logger.record(\"live/avg_cash_weight\", df_steps['weight_0'].mean())\n","\n","            weight_cols = [col for col in df_steps.columns if col.startswith('weight_')]\n","            if len(weight_cols) > 1:\n","                max_asset_weight = df_steps[weight_cols[1:]].max(axis=1).mean()\n","                self.logger.record(\"live/max_asset_weight\", max_asset_weight)\n","\n","        # Speicher leeren\n","        self.rollout_step_infos = []\n","        self.rollout_episode_infos = []\n","\n","    def _run_evaluation_and_log_table(self):\n","        \"\"\" 4. & 5. Startet EVAL-Episode, loggt Trajektorie und speichert bestes Modell. \"\"\"\n","        if self.verbose > 0:\n","            print(f\"--- [Callback] Starte EVAL & Trajectory-Logging (Schritt: {self.num_timesteps}) ---\")\n","\n","        trajectory_log = []\n","        obs = self.eval_env.reset()\n","        done = False\n","        total_reward = 0.0\n","\n","        while not done:\n","            action, _ = self.model.predict(obs, deterministic=True)\n","            obs, reward, done, info = self.eval_env.step(action)\n","\n","            step_info = info[0]\n","            trajectory_log.append(step_info)\n","            total_reward += reward[0]\n","\n","            if done[0]:\n","                break\n","\n","        # Logge die detaillierte Trajektorien-Tabelle\n","        try:\n","            df = pd.DataFrame(trajectory_log)\n","            debug_table = wandb.Table(dataframe=df)\n","            wandb.log({f\"eval/trajectory_step_{self.num_timesteps}\": debug_table}, step=self.num_timesteps)\n","            if self.verbose > 0:\n","                print(f\"--- [Callback] EVAL-Tabelle mit {len(df)} Schritten geloggt. ---\")\n","        except Exception as e:\n","            print(f\"--- [Callback] FEHLER beim Loggen der W&B-Tabelle: {e} ---\")\n","\n","        # Logge die Standard-Evaluierungs-Metriken\n","        mean_reward = total_reward\n","        mean_ep_length = len(trajectory_log)\n","        self.logger.record(\"eval/mean_reward\", mean_reward)\n","        self.logger.record(\"eval/mean_ep_length\", mean_ep_length)\n","\n","        # (Die Rekursions-Zeile ist bereits entfernt)\n","\n","        # Speichere das beste Modell\n","        if mean_reward > self.best_mean_reward:\n","            self.best_mean_reward = mean_reward\n","            save_path = os.path.join(self.log_path, \"best_model.zip\")\n","            if self.verbose > 0:\n","                print(f\"--- [Callback] Neues bestes Modell gespeichert (Reward: {mean_reward:.2f}) ---\")\n","            self.model.save(save_path)\n","\n","    def _on_training_end(self):\n","        self.eval_env.close()\n","        print(\"--- [Callback] Training beendet. Eval-Umgebung geschlossen. ---\")\n","\n","\n","print(\"--- Alle Klassen (inkl. UnifiedObservabilityCallback V2) definiert ---\")"],"metadata":{"trusted":true,"id":"AyaMPq8HE1FG","executionInfo":{"status":"ok","timestamp":1763289057595,"user_tz":-60,"elapsed":149,"user":{"displayName":"Christoph Nachname","userId":"04640672557127032436"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"49b1d07b-7be9-48dd-f312-8581e7d776c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Alle Klassen (inkl. UnifiedObservabilityCallback V2) definiert ---\n"]}],"execution_count":6},{"cell_type":"code","source":["import pandas as pd\n","from stable_baselines3.common.callbacks import BaseCallback\n","\n","# --- Helfer-Funktion für SubprocVecEnv (Parallelisierung) ---\n","def create_env(feature_csv_path: str, env_config: dict, start_date: str, end_date: str) -> gym.Env:\n","    \"\"\"Erstellt eine Instanz der Umgebung und wickelt sie in Monitor ein.\n","    Lädt die Daten direkt in der Worker-Umgebung und filtert sie.\n","    \"\"\"\n","    # Lade die vollständigen CSV-Daten im Worker-Prozess\n","    # Annahme: Die CSV hat Datetime-Index und Multi-Level-Spalten\n","    try:\n","        full_data_df = pd.read_csv(feature_csv_path, index_col=0, parse_dates=True, header=[0, 1])\n","        # Optional: Print zur Bestätigung, dass der Worker lädt\n","        print(f\"(Worker) CSV geladen. Form: {full_data_df.shape}\")\n","    except Exception as e:\n","        print(f\"(Worker) FEHLER beim Laden der CSV in create_env: {e}\")\n","        raise # Fehler weitergeben, damit der Worker abstürzt und der Hauptprozess es bemerkt\n","\n","    # Filtere die Daten für den spezifischen Zeitraum dieser Umgebung-Instanz\n","    data_for_env = full_data_df[(full_data_df.index >= start_date) & (full_data_df.index <= end_date)]\n","\n","    env = PortfolioEnv(\n","        data_df=data_for_env, # Übergebe das korrekt gefilterte DataFrame\n","        **env_config           # Entpacke die Umgebungskonfiguration\n","    )\n","    env = Monitor(env)\n","    return env\n","\n","# --- Haupt-Trainingsfunktion (für W&B Sweep) ---\n","def train(config):\n","    \"\"\"\n","    Haupt-Trainingsfunktion.\n","    \"\"\"\n","\n","    # --- 1. W&B Run initialisieren ---\n","    run = wandb.init(\n","        project=config[\"project_name\"],\n","        config=config,\n","        name=config[\"run_name\"],\n","        sync_tensorboard=True,\n","        monitor_gym=True,\n","        save_code=True,\n","        reinit=\"finish_previous\",\n","        dir=config[\"wandb_log_dir\"]\n","    )\n","    config = wandb.config\n","\n","    # --- 2. Umgebungskonfigurationen vorbereiten ---\n","    # data_cfg ist jetzt nicht mehr direkt nötig für create_env, da der Pfad direkt übergeben wird\n","    env_cfg = {\n","        \"initial_balance\": config.initial_balance,\n","        \"window_size\": config.window_size,\n","        \"transaction_cost_pct\": config.transaction_cost_pct\n","    }\n","\n","    # --- 3. Erstelle TRAIN-Umgebung (Parallel) ---\n","    print(f\"Erstelle {config.num_cpu_cores} parallele TRAIN-Umgebungen...\")\n","    train_env_partial = partial(\n","        create_env,\n","        feature_csv_path=config.feature_csv_path, # Pfad direkt übergeben\n","        env_config=env_cfg,\n","        start_date=config.train_start_date,\n","        end_date=config.train_end_date\n","    )\n","    train_env = SubprocVecEnv([train_env_partial for _ in range(config.num_cpu_cores)])\n","\n","    # --- 4. Erstelle EVAL-Umgebungs-\"Fabrik\" (wird an Callback übergeben) ---\n","    print(\"Erstelle EVAL-Umgebungs-Fabrik...\")\n","    eval_env_fn = partial(\n","        create_env,\n","        feature_csv_path=config.feature_csv_path, # Pfad direkt übergeben\n","        env_config=env_cfg,\n","        start_date=config.eval_start_date,\n","        end_date=config.eval_end_date\n","    )\n","\n","    # --- 5. Policy-Architektur definieren ---\n","    policy_kwargs = dict(\n","        features_extractor_class=CustomCombinedExtractor,\n","        features_extractor_kwargs=dict(\n","             extractor_type=config.extractor_type,\n","            hidden_size=config.extractor_hidden_size\n","        ),\n","        net_arch=dict(\n","            pi=config.policy_pi_arch,\n","            vf=config.policy_vf_arch\n","        )\n","    )\n","\n","    # --- 6. Callbacks definieren ---\n","    callback_list = []\n","\n","    # Standard W&B Callback (leitet SB3-Logs an W&B weiter)\n","    if config.use_wandb:\n","        wandb_callback = WandbCallback(model_save_path=None, verbose=0)\n","        callback_list.append(wandb_callback)\n","\n","    # Unser \"Super-Callback\", der alles andere ersetzt\n","    if config.save_model:\n","        save_path = os.path.join(config.model_save_dir, config.run_name)\n","        os.makedirs(save_path, exist_ok=True)\n","        print(f\"Modell-Speicherung und Trajectory-Logs in: {save_path}\")\n","\n","        # Definiere die Frequenz:\n","        # Wir setzen eval_freq=1, damit der Callback JEDEN Rollout evaluiert.\n","        # (Jedes Mal, wenn n_steps = 4096 Schritte gesammelt wurden)\n","        unified_callback = UnifiedObservabilityCallback(\n","            eval_env_fn=eval_env_fn,\n","            eval_freq=1, # Evaluiere nach JEDEM Rollout\n","            log_path=save_path,\n","            verbose=1 # (Setze auf 1, um Logs vom Callback zu sehen)\n","        )\n","        callback_list.append(unified_callback)\n","\n","    # --- 7. Modell initialisieren (PPO) ---\n","    model = PPO(\n","        policy=CustomActorCriticPolicy,\n","        env=train_env,\n","        n_steps=config.n_steps,\n","        batch_size=config.batch_size,\n","        n_epochs=config.n_epochs,\n","        learning_rate=config.learning_rate,\n","        gamma=config.gamma,\n","        gae_lambda=config.gae_lambda,\n","        clip_range=config.clip_range,\n","        vf_coef=config.vf_coef,\n","        ent_coef=config.ent_coef,\n","        policy_kwargs=policy_kwargs,\n","        # tensorboard_log=f\"runs/{run.id}\", # Removed to prevent conflict with WandbCallback\n","        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n","        verbose=0\n","    )\n","\n","    print(f\"--- PPO-Modell initialisiert (Gerät: {model.device}) ---\")\n","\n","    # --- 8. Training starten ---\n","    print(f\"--- Starte Training für {config.total_timesteps} Timesteps ---\")\n","    try:\n","        model.learn(\n","            total_timesteps=config.total_timesteps,\n","            callback=CallbackList(callback_list),\n","            progress_bar=False # Set to False to avoid conflicts with wandb\n","        )\n","        print(\"--- Training abgeschlossen ---\")\n","    except Exception as e:\n","        print(f\"FEHLER während des Trainings: {e}\")\n","    finally:\n","        # --- 9. Aufräumen ---\n","        train_env.close()\n","        # EvalEnv wird jetzt automatisch vom Callback geschlossen\n","        run.finish()\n","        print(\"--- Run beendet und Umgebungen geschlossen ---\")\n","\n","# ----------------------------------------------------------------------\n","# STARTPUNKT (WICHTIG für SubprocVecEnv) - hier bleibt die globale config\n","# ----------------------------------------------------------------------\n","if __name__ == \"__main__\":\n","    global_config = globals().get('config')\n","    if global_config:\n","        train(global_config)\n","    else:\n","        print(\"FEHLER: Globale 'config' wurde nicht gefunden.\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T06:04:46.268465Z","iopub.execute_input":"2025-11-08T06:04:46.26868Z","iopub.status.idle":"2025-11-08T06:05:23.657803Z","shell.execute_reply.started":"2025-11-08T06:04:46.268664Z","shell.execute_reply":"2025-11-08T06:05:23.656865Z"},"id":"Gi7s3G4sE1FG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf1c0a3a-a1a9-415b-a6fd-05eb0444ff5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find PPO_Training_V3_CSV_Input.ipynb.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"]}],"execution_count":null}]}