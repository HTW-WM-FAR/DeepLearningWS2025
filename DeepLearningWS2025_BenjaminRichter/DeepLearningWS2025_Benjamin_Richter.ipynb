{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b96d09-ff0c-4f6b-98d4-b737d092baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -U \\\n",
    "    pandas \\\n",
    "    numpy \\\n",
    "    scikit-learn \\\n",
    "    torch \\\n",
    "    transformers \\\n",
    "    datasets \\\n",
    "    huggingface_hub \\\n",
    "    fsspec \\\n",
    "    accelerate \\\n",
    "    evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67114f27-56b8-4074-b0b2-38ee204b8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b49fc-b40b-4df3-aa46-ea565188455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b15c0-80da-4700-b963-3879b93c33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.jsonl', 'test': 'test.jsonl'}\n",
    "\n",
    "df_train = pd.read_json(\n",
    "    \"hf://datasets/SetFit/enron_spam/\" + splits[\"train\"],\n",
    "    lines=True\n",
    ")\n",
    "df_test = pd.read_json(\n",
    "    \"hf://datasets/SetFit/enron_spam/\" + splits[\"test\"],\n",
    "    lines=True\n",
    ")\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1feed-ece4-4d77-91d6-559fd1df69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.label.value_counts())\n",
    "print(df_test.label.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d419a5-1ec7-42a9-9bd5-3ea0e44f8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Naive Bayes Baseline (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca595271-f555-41f4-81e1-f7f02ff697f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(df_train[\"text\"])\n",
    "X_test_tfidf = vectorizer.transform(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff690171-adf0-4241-9529-c8178bcb8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, df_train[\"label\"])\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "y_proba_nb = nb_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(df_test[\"label\"], y_pred_nb))\n",
    "print(classification_report(\n",
    "    df_test[\"label\"], y_pred_nb,\n",
    "    target_names=[\"Ham\", \"Spam\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74977fb-915a-4834-a74b-2bb644ea13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_test[\"label\"], y_pred_nb)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642dac3-39cf-4f39-8349-eb665feef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_proba_nb = nb_model.predict_log_proba(X_test_tfidf)\n",
    "\n",
    "y_pred_nb = log_proba_nb.argmax(axis=1)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(df_test[\"label\"], y_pred_nb))\n",
    "print(classification_report(\n",
    "    df_test[\"label\"], y_pred_nb,\n",
    "    target_names=[\"Ham\", \"Spam\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db5e21-40af-4d68-988b-a1f3dfc36cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.feature_log_prob_.shape\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "log_prob_df = pd.DataFrame(\n",
    "    nb_model.feature_log_prob_,\n",
    "    columns=feature_names,\n",
    "    index=[\"Ham\", \"Spam\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef23c9-bd4b-407b-9246-d7f8fd2ce572",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_df.loc[\"Spam\", \"free\"] - log_prob_df.loc[\"Ham\", \"free\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47640d-a852-4dfa-9431-12e18d41d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_prob_df.loc[\"Spam\", \"company\"] - log_prob_df.loc[\"Ham\", \"company\"])\n",
    "print(log_prob_df.loc[\"Spam\", \"new\"] - log_prob_df.loc[\"Ham\", \"new\"])\n",
    "print(log_prob_df.loc[\"Spam\", \"fw\"] - log_prob_df.loc[\"Ham\", \"fw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65595616-d185-48b7-b257-dee4e5a5f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_df.loc[\"Spam\",\"new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad57af-1eeb-41bd-924d-eaa5395a31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds = (\n",
    "    log_prob_df.loc[\"Spam\"] -\n",
    "    log_prob_df.loc[\"Ham\"]\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "log_odds.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f483a3-39b6-4cde-8e47-8ca305d0ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a4620-087d-4ac5-82ee-6c4ac689a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nb = pd.DataFrame({\n",
    "    \"text\": df_test[\"text\"].values,\n",
    "    \"true_label\": df_test[\"label\"].values,\n",
    "    \"predicted_label\": y_pred_nb,\n",
    "    \"prob_ham\": y_proba_nb[:, 0],\n",
    "    \"prob_spam\": y_proba_nb[:, 1],\n",
    "})\n",
    "\n",
    "results_nb[\"confidence\"] = results_nb[[\"prob_ham\", \"prob_spam\"]].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff5b24-b617-4d55-8b99-bd77813cfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_nb = results_nb[\n",
    "    results_nb.true_label != results_nb.predicted_label\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836362f-f089-4bd1-91f4-e9597d8732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_nb = misclassified_nb[\n",
    "    (misclassified_nb.true_label == 0) &\n",
    "    (misclassified_nb.predicted_label == 1)\n",
    "]\n",
    "\n",
    "false_negatives_nb = misclassified_nb[\n",
    "    (misclassified_nb.true_label == 1) &\n",
    "    (misclassified_nb.predicted_label == 0)\n",
    "]\n",
    "confident_wrong = results_nb[\n",
    "    (results_nb.true_label != results_nb.predicted_label) &\n",
    "    (results_nb.confidence > 0.9)\n",
    "]\n",
    "\n",
    "confident_wrong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa36544-dc66-4d52-9a2b-fcc94a9839c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nb_examples(df, n=5):\n",
    "    for _, row in df.head(n).iterrows():\n",
    "        print(\"=\" * 80)\n",
    "        print(\"TRUE LABEL:\", \"Spam\" if row.true_label == 1 else \"Ham\")\n",
    "        print(\"PREDICTED:\", \"Spam\" if row.predicted_label == 1 else \"Ham\")\n",
    "        print(\"EMAIL TEXT:\")\n",
    "        print(row.text[:1000])  # truncate long emails\n",
    "        print()\n",
    "\n",
    "\n",
    "print(\"\\nFALSE POSITIVES\")\n",
    "print_nb_examples(false_positives_nb, n=5)\n",
    "\n",
    "print(\"\\nFALSE NEGATIVES\")\n",
    "print_nb_examples(false_negatives_nb, n=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7470b94-a17c-442a-bd67-bd07e478eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Common Words in Spam vs Ham Emails (Stopwords removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66484c70-6147-44f5-b532-54e1cdeb6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e7afac-95e0-4c99-b522-f8bb5994a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(ENGLISH_STOP_WORDS) | {\"com\", \"www\", \"http\", \"subject\", \"message\", \"ect\", \"hou\"}\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords and len(t) > 2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec75744-d6e2-488b-ae40-9e3ba92d7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_texts = df_train[df_train[\"label\"] == 1][\"text\"]\n",
    "ham_texts  = df_train[df_train[\"label\"] == 0][\"text\"]\n",
    "\n",
    "spam_tokens = []\n",
    "ham_tokens = []\n",
    "\n",
    "for text in spam_texts:\n",
    "    spam_tokens.extend(tokenize(text))\n",
    "\n",
    "for text in ham_texts:\n",
    "    ham_tokens.extend(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ddea5-9f42-4bf5-91da-9eb92676c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_counter = Counter(spam_tokens)\n",
    "ham_counter = Counter(ham_tokens)\n",
    "\n",
    "spam_counter.most_common(20), ham_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5cbec-5721-4a0e-ab00-70a9b12ddc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Odds (NOT USED!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b381bf-606f-4a49-a24d-c0866f5b4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "vocab = set(spam_counter.keys()) | set(ham_counter.keys())\n",
    "\n",
    "def log_odds(word, alpha=1):\n",
    "    spam_count = spam_counter.get(word, 0) + alpha\n",
    "    ham_count = ham_counter.get(word, 0) + alpha\n",
    "    return math.log(spam_count / ham_count)\n",
    "\n",
    "log_odds_scores = {\n",
    "    word: log_odds(word) for word in vocab\n",
    "}\n",
    "\n",
    "top_spam_words = sorted(\n",
    "    log_odds_scores.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:20]\n",
    "\n",
    "top_ham_words = sorted(\n",
    "    log_odds_scores.items(),\n",
    "    key=lambda x: x[1]\n",
    ")[:20]\n",
    "\n",
    "top_spam_words, top_ham_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd88c4-b69c-460f-9899-b90f560d8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b755a3-b7a1-4a87-ac77-ff7c971d8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5042ce-230b-46b4-a7a5-2f6be5b86588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "\n",
    "torch.set_num_threads(2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74f053-0ee3-4425-89de-93d75d160400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if graphics card uses memory\n",
    "#!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76820a-5336-427e-bf53-c777a7b0d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available in PyTorch:\", torch.cuda.is_available())\n",
    "print(\"CUDA version PyTorch was built with:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9053354-c058-43e4-8ae6-349577e75886",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmailDataset(\n",
    "    df_train[\"text\"].tolist(),\n",
    "    df_train[\"label\"].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = EmailDataset(\n",
    "    df_test[\"text\"].tolist(),\n",
    "    df_test[\"label\"].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7730745-3c41-412c-a5e4-8d7678879d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063f464-9682-4e27-9cf3-7c49a5e5e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bea5d-a63d-4217-aece-6067c03f00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "all_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        start_idx = i * test_loader.batch_size\n",
    "        batch_size = labels.size(0)\n",
    "        all_indices.extend(range(start_idx, start_idx + batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed7da1-3e5f-4f55-a276-45f7d758e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
    "recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
    "f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aadff2-70a6-40b6-b663-89c8ea2e626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df229d6-6699-467a-87cf-75697842fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"index\": all_indices,\n",
    "    \"text\": df_test.iloc[all_indices][\"text\"].values,\n",
    "    \"true_label\": all_labels,\n",
    "    \"predicted_label\": all_preds\n",
    "})\n",
    "\n",
    "misclassified = results_df[results_df.true_label != results_df.predicted_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db3fc1-e454-418d-9985-a832166e2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = misclassified[\n",
    "    (misclassified.true_label == 0) &\n",
    "    (misclassified.predicted_label == 1)\n",
    "]\n",
    "\n",
    "false_negatives = misclassified[\n",
    "    (misclassified.true_label == 1) &\n",
    "    (misclassified.predicted_label == 0)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f07a31-dece-4e5a-8669-01fa3a7523b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_examples(df, n=5):\n",
    "    for i, row in df.head(n).iterrows():\n",
    "        print(\"=\"*80)\n",
    "        print(\"TRUE LABEL:\", \"Spam\" if row.true_label == 1 else \"Ham\")\n",
    "        print(\"Predicted:\", \"Spam\" if row.predicted_label == 1 else \"Ham\")\n",
    "        print(\"Email text:\")\n",
    "        print(row.text[:1000]) \n",
    "        print()\n",
    "\n",
    "print(\"FALSE POSITIVES\")\n",
    "print_examples(false_positives, n=5)\n",
    "\n",
    "print(\"\\nFALSE NEGATIVES\")\n",
    "print_examples(false_negatives, n=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f9735",
   "metadata": {},
   "source": [
    "Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680de59-e832-45bd-9784-db95d2191c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.attn_implementation = \"eager\"\n",
    "model.config.output_attentions = True\n",
    "model.config.return_dict = True\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "attentions = outputs.attentions\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "attn = attentions[-1][0]\n",
    "attn_mean = attn.mean(dim=0)\n",
    "cls_attention = attn_mean[0]\n",
    "\n",
    "token_attention = list(\n",
    "    zip(tokens, cls_attention.cpu().numpy())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d39c3-6e2a-476a-b8c5-c8cc617b6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = sorted(\n",
    "    token_attention,\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for tok, score in top_tokens[:15]:\n",
    "    print(f\"{tok:>15s}  {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834972fa-b149-4491-881d-235854b6f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e9d90-10b5-4da3-a17b-6271c181b03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
