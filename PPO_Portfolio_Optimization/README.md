Deep Reinforcement Learning for Portfolio Optimization (S&P 500)

Dieses Repository enthÃ¤lt den Code und die Dokumentation fÃ¼r eine Seminararbeit im Bereich Deep Reinforcement Learning (DRL) im quantitativen Finanzwesen.

Ziel des Projekts war die Entwicklung eines PPO-Agenten (Proximal Policy Optimization), der ein Portfolio aus S&P 500 Aktien dynamisch verwaltet und dabei den Markt unter BerÃ¼cksichtigung realer Transaktionskosten schlÃ¤gt.

ğŸ“ˆ Ergebnisse & Highlights

Performance: Der trainierte Agent erzielt eine leicht hÃ¶here risikoadjustierte Rendite als der Benchmark (S&P 500 Buy & Hold) im Evaluationszeitraum (2020â€“2023).

Architektur: Custom LSTM-Feature-Extractor mit Dropout zur Vermeidung von Overfitting.

Robustheit: Erfolgreiches Lernen von Kosteneffizienz durch Implementierung einer Turnover Penalty.

Daten: Training auf 14 Jahren echter S&P 500 Daten (2006â€“2019), inklusive der Finanzkrise 2008.

ğŸ“‚ Projektstruktur

Um das Repository performant zu halten und GitHub-Limits zu umgehen, werden groÃŸe DatensÃ¤tze und Modell-Checkpoints nicht direkt hochgeladen. Die Struktur ist wie folgt aufgebaut:

PPO_Portfolio_Optimization/
â”‚
â”œâ”€â”€ data/                    # Lokaler Speicher fÃ¼r CSV-Daten (wird durch Notebooks generiert)
â”‚   â”œâ”€â”€ raw/                 # Rohdaten von yfinance (wird ignoriert durch .gitignore)
â”‚   â””â”€â”€ processed/           # Bereinigte Features (wird ignoriert durch .gitignore)
â”‚
â”œâ”€â”€ models/                  # Speicherort fÃ¼r trainierte Agenten (lokal)
â”‚
â”œâ”€â”€ notebooks/               # Der Kern des Projekts: 5 sequentielle Schritte
â”‚   â”œâ”€â”€ 00_Data_Generator_Synthetic.ipynb      # Testet die Pipeline mit synthetischen Daten
â”‚   â”œâ”€â”€ 01_Data_Downloader_Real.ipynb          # LÃ¤dt echte S&P 500 Daten herunter
â”‚   â”œâ”€â”€ 02_Data_Validation_Features.ipynb      # Feature Engineering (RSI, MACD, VIX)
â”‚   â”œâ”€â”€ 03_PPO_Training.ipynb                  # Training des Agenten
â”‚   â””â”€â”€ 04_Final_Evaluation_Quantstats.ipynb   # Backtesting und Reporting
â”‚
â”œâ”€â”€ results/                 # Output der Evaluation
â”‚   â””â”€â”€ reports/             # HTML-Reports von QuantStats
â”‚
â”œâ”€â”€ requirements.txt         # BenÃ¶tigte Python-Bibliotheken
â””â”€â”€ README.md                # Diese Datei


ğŸš€ Installation & AusfÃ¼hrung (Reproduzierbarkeit)

1. Repository klonen

git clone [https://github.com/DEIN_USERNAME/PPO-Portfolio-Seminar.git](https://github.com/DEIN_USERNAME/PPO-Portfolio-Seminar.git)
cd PPO-Portfolio-Seminar


2. Umgebung einrichten

Es wird empfohlen, eine virtuelle Umgebung (venv oder conda) zu nutzen.

pip install -r requirements.txt


3. Pipeline ausfÃ¼hren

Die Notebooks sind sequentiell aufgebaut. Da die Rohdaten nicht im Repository liegen, mÃ¼ssen die Notebooks in dieser Reihenfolge ausgefÃ¼hrt werden:

01_Data_Downloader_Real.ipynb:

LÃ¤dt historische S&P 500 Daten (2006â€“2024) via yfinance herunter.

Speichert data/raw/sp500_20_years_data.csv.

02_Data_Validation_Features.ipynb:

Bereinigt Daten, fÃ¼llt LÃ¼cken (Forward Fill) und berechnet technische Indikatoren.

Speichert data/processed/features_cleaned.csv.

03_PPO_Training.ipynb:

Startet das Training des PPO-Agenten.

Speichert das Modell unter models/.

Nutzt Weights & Biases fÃ¼r das Logging (optional).

04_Final_Evaluation_Quantstats.ipynb:

LÃ¤dt das beste Modell (best_model.zip).

FÃ¼hrt einen Backtest auf "Out-of-Sample" Daten (2020â€“2023) durch.

Erstellt einen HTML-Report mit Benchmark-Vergleich.

ğŸ§  Methodik

Algorithmus: PPO (Stable Baselines 3) mit MultiInputPolicy.

Environment: Gymnasium Custom Env mit kontinuierlichem Action-Space (Gewichtung der Aktien + Cash).

Reward Function: Log-Returns mit Scaling-Faktor (x100) und Bestrafung fÃ¼r hohen Umsatz (Turnover Penalty), um Overtrading zu vermeiden.

Training: 30 Millionen Timesteps auf Daten von 2006 bis 2019.

Evaluation: Out-of-Sample Test auf den Jahren 2020 bis 2023 (beinhaltet Corona-Crash und Inflationsphase).

âš ï¸ Hinweis zu den Daten

Aufgrund der DateigrÃ¶ÃŸenbeschrÃ¤nkung von GitHub (>100MB) sind die Dateien sp500_20_years_data.csv und features_cleaned.csv nicht direkt im Repository enthalten.

Sie werden jedoch automatisch und deterministisch generiert, sobald Sie die Notebooks 01 und 02 ausfÃ¼hren. Dies stellt die Reproduzierbarkeit der Ergebnisse sicher.

ğŸ“§ Kontakt
Autor: ChristophBieritz1989@googlemail.com
UniversitÃ¤t: HTW BERLIN
Kurs: Seminar: Deep Learning