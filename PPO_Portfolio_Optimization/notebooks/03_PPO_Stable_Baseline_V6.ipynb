{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4ChdipO5KQ50",
    "outputId": "baf6317f-8548-4226-b564-81279e58e09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in ./.local/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: wandb in ./.local/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: shimmy in /opt/conda/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: stable-baselines3[extra] in ./.local/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from gymnasium) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./.local/lib/python3.9/site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./.local/lib/python3.9/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (3.9.4)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
      "Requirement already satisfied: pygame in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.19.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (5.9.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (0.11.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from stable-baselines3[extra]) (9.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.local/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.local/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.local/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.local/lib/python3.9/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.local/lib/python3.9/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.local/lib/python3.9/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.local/lib/python3.9/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.local/lib/python3.9/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.local/lib/python3.9/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.local/lib/python3.9/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./.local/lib/python3.9/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.local/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.local/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.local/lib/python3.9/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./.local/lib/python3.9/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.9/site-packages (from triton==3.4.0->torch) (68.2.2)\n",
      "Requirement already satisfied: click>=8.0.1 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: eval-type-backport in ./.local/lib/python3.9/site-packages (from wandb) (0.3.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.local/lib/python3.9/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from wandb) (23.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from wandb) (4.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3 in ./.local/lib/python3.9/site-packages (from wandb) (2.12.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.local/lib/python3.9/site-packages (from wandb) (2.46.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.local/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (6.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->stable-baselines3[extra]) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 1. Installationen\n",
    "# ----------------------------------------------------------------------\n",
    "# Wir installieren gymnasium, stable-baselines3, wandb und shimmy für Kompatibilität\n",
    "!pip install gymnasium stable-baselines3[extra] wandb shimmy pandas numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "usf9fHh4E1FC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 06:24:27.149666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764051867.167065    9414 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764051867.172632    9414 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764051867.191642    9414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051867.191659    9414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051867.191661    9414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051867.191662    9414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-25 06:24:27.196077: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lokale Umgebung.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristoph-bieritz\u001b[0m (\u001b[33mcb-ml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# 2. Imports & Konfiguration\n",
    "# ----------------------------------------------------------------------\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "# Stable Baselines 3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n",
    "\n",
    "# W&B\n",
    "import wandb\n",
    "\n",
    "# Colab Setup\n",
    "ENV = \"colab\"\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    drive.mount('/content/drive')\n",
    "    WANDB_API_KEY = userdata.get('WANDB_API_KEY') \n",
    "    BASE_DIR = '/content/drive/MyDrive/01_Data/projects/PPO_portfolio_optimization'\n",
    "    print(\"Umgebung: Google Colab. Drive gemountet.\")\n",
    "except ImportError:\n",
    "    ENV = \"local\"\n",
    "    WANDB_API_KEY = \"5040c3fbca0b98e69a044c329e27480694067462\" # Fallback\n",
    "    BASE_DIR = \"./\"\n",
    "    print(\"Lokale Umgebung.\")\n",
    "\n",
    "if WANDB_API_KEY:\n",
    "    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "    wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# --- CONFIG UPDATE ---\n",
    "config = {\n",
    "    \"project_name\": \"PPO_Portfolio_SP500\",\n",
    "    \"run_name\": f\"PPO_LSTM_Transfer_{uuid.uuid4().hex[:8]}\", # Neuer Name\n",
    "    \"use_wandb\": True,\n",
    "    \"save_model\": True,\n",
    "    \"feature_csv_path\": os.path.join(BASE_DIR, 'processed_data', 'features_cleaned.csv'),\n",
    "    \"model_save_dir\": os.path.join(BASE_DIR, 'models'),\n",
    "    \"wandb_log_dir\": os.path.join(BASE_DIR, 'data', 'wandb_logs'),\n",
    "    \n",
    "    # --- MODELL LADEN (CLOUD) ---\n",
    "    # Hier den Pfad zum Artifact einfügen, falls du fortsetzen willst.\n",
    "    # Format: 'entity/project/artifact_name:version' oder ':alias'\n",
    "    # Beispiel: 'cb-ml/PPO_Portfolio_SP500/PPO_LSTM_CSV_f074b6dc_BEST:latest'\n",
    "    \"load_artifact_path\": \"\",  # <-- HIER EINFÜGEN ZUM LADEN (sonst leer lassen)\n",
    "    \n",
    "    \"train_start_date\": '2006-01-01',\n",
    "    \"train_end_date\": '2019-12-31',\n",
    "    \"eval_start_date\": '2020-01-01',\n",
    "    \"eval_end_date\": '2023-12-31',\n",
    "    \n",
    "    \"initial_balance\": 10000.0,\n",
    "    \"window_size\": 30,\n",
    "    \"transaction_cost_pct\": 0.0005,\n",
    "    \n",
    "    \"total_timesteps\": 30_000_000, \n",
    "    \"learning_rate\": 0.0003,       \n",
    "    \"extractor_rnn_dropout\": 0.2,  \n",
    "    \n",
    "    \"num_cpu_cores\": 4,\n",
    "    \"n_steps\": 4096,\n",
    "    \"batch_size\": 1024,\n",
    "    \"n_epochs\": 5,\n",
    "    \"ent_coef\": 0.0001,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"extractor_type\": \"LSTM\",\n",
    "    \"extractor_hidden_size\": 128,\n",
    "    \"policy_pi_arch\": [64],\n",
    "    \"policy_vf_arch\": [64]\n",
    "}\n",
    "\n",
    "os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "os.makedirs(config['wandb_log_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1763631787156,
     "user": {
      "displayName": "Christoph Nachname",
      "userId": "04640672557127032436"
     },
     "user_tz": -60
    },
    "id": "GvvxJD8DE1FE",
    "outputId": "a2ba77db-2807-421d-bf50-da0bd2c984ce"
   },
   "outputs": [],
   "source": [
    "# 4. Environment Class (MIT SMART DATA LOADER)\n",
    "# ----------------------------------------------------------------------\n",
    "class PortfolioEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, data_config, env_config, start_date, end_date):\n",
    "        super().__init__()\n",
    "        self.data_config = data_config\n",
    "        self.env_config = env_config\n",
    "        self.start_date_str = start_date\n",
    "        self.end_date_str = end_date\n",
    "        \n",
    "        self.window_size = self.env_config['window_size']\n",
    "        self.initial_balance = self.env_config['initial_balance']\n",
    "        self.transaction_cost_pct = self.env_config['transaction_cost_pct']\n",
    "        \n",
    "        # 1. Daten laden (Robust)\n",
    "        self._load_and_reshape_data()\n",
    "        self._set_time_slices()\n",
    "        \n",
    "        # 2. Spaces definieren\n",
    "        self.num_portfolio_components = self.num_assets + 1\n",
    "        self.portfolio_value = self.initial_balance\n",
    "        self.prev_portfolio_value = self.initial_balance\n",
    "        self.portfolio_weights = np.zeros(self.num_portfolio_components, dtype=np.float32)\n",
    "        self.portfolio_weights[0] = 1.0\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-20.0, high=20.0, shape=(self.num_portfolio_components,), dtype=np.float32)\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"market_data\": spaces.Box(low=-np.inf, high=np.inf, shape=(self.window_size, self.num_assets, self.num_features), dtype=np.float32),\n",
    "            \"portfolio_weights\": spaces.Box(low=0.0, high=1.0, shape=(self.num_portfolio_components,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def _load_and_reshape_data(self):\n",
    "        \"\"\"Lädt CSV und erkennt automatisch Format (Long vs Wide)\"\"\"\n",
    "        csv_path = self.data_config.get('feature_csv_path')\n",
    "        print(f\"(Worker) Lade Daten: {csv_path}\")\n",
    "        \n",
    "        # Erstmal generisch laden\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # CHECK: Ist es das 'Long Format' (Date, Ticker als Spalten)?\n",
    "        if 'Date' in df.columns and 'Ticker' in df.columns:\n",
    "            # Datum konvertieren\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            # Index setzen\n",
    "            df.set_index(['Date', 'Ticker'], inplace=True)\n",
    "            \n",
    "            # Unstacken zu Wide Format: Index=Date, Cols=(Feature, Ticker)\n",
    "            df_wide = df.unstack(level='Ticker')\n",
    "            \n",
    "            # Metadaten extrahieren\n",
    "            self.feature_names = df_wide.columns.levels[0].tolist()\n",
    "            self.asset_names = df_wide.columns.levels[1].tolist()\n",
    "            \n",
    "            # Daten bereinigen (Forward Fill für fehlende Tage)\n",
    "            df_wide = df_wide.ffill().bfill()\n",
    "            \n",
    "            # In 3D-Tensor umwandeln (Time, Assets, Features)\n",
    "            total_timesteps = len(df_wide)\n",
    "            self.num_assets = len(self.asset_names)\n",
    "            self.num_features = len(self.feature_names)\n",
    "            \n",
    "            # WICHTIG: Sortierung sicherstellen für korrekten Reshape\n",
    "            values = df_wide.stack(level='Ticker', future_stack=True).values\n",
    "            \n",
    "            self._market_data_numpy = values.reshape(total_timesteps, self.num_assets, self.num_features).astype(np.float32)\n",
    "            self.full_data_index = df_wide.index\n",
    "            \n",
    "            # Versuche Returns-Spalte zu finden (für Reward Berechnung)\n",
    "            try:\n",
    "                self.return_feature_idx = next(i for i, name in enumerate(self.feature_names) \n",
    "                                             if 'return' in name.lower() or 'pct' in name.lower() or 'change' in name.lower())\n",
    "                print(f\"Return-Feature gefunden an Index {self.return_feature_idx}: {self.feature_names[self.return_feature_idx]}\")\n",
    "            except StopIteration:\n",
    "                print(\"WARNUNG: Kein explizites Return-Feature gefunden. Nutze Index 0.\")\n",
    "                self.return_feature_idx = 0\n",
    "                \n",
    "        else:\n",
    "            # Fallback: Annahme MultiIndex Header im CSV\n",
    "            df = pd.read_csv(csv_path, header=[0, 1], index_col=0, parse_dates=True)\n",
    "            df.sort_index(inplace=True)\n",
    "            self.full_data_index = df.index\n",
    "            self.num_features = df.columns.get_level_values(0).nunique()\n",
    "            self.num_assets = df.columns.get_level_values(1).nunique()\n",
    "            self._market_data_numpy = df.stack(level=1, future_stack=True).values.reshape(\n",
    "                len(df), self.num_assets, self.num_features\n",
    "            ).astype(np.float32)\n",
    "            self.return_feature_idx = 0 # Fallback\n",
    "\n",
    "    def _set_time_slices(self):\n",
    "        start_ts = pd.to_datetime(self.start_date_str)\n",
    "        end_ts = pd.to_datetime(self.end_date_str)\n",
    "        \n",
    "        # Robuste Index-Suche\n",
    "        if start_ts < self.full_data_index[0]: start_ts = self.full_data_index[0]\n",
    "        if end_ts > self.full_data_index[-1]: end_ts = self.full_data_index[-1]\n",
    "\n",
    "        start_idx = self.full_data_index.searchsorted(start_ts)\n",
    "        end_idx = self.full_data_index.searchsorted(end_ts)\n",
    "        \n",
    "        if end_idx >= len(self.full_data_index): end_idx = len(self.full_data_index) - 1\n",
    "\n",
    "        self.start_tick = max(start_idx, self.window_size)\n",
    "        self.end_tick = end_idx\n",
    "        self.current_step = self.start_tick\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.start_tick\n",
    "        self.portfolio_value = self.initial_balance\n",
    "        self.prev_portfolio_value = self.initial_balance\n",
    "        self.portfolio_weights = np.zeros(self.num_portfolio_components, dtype=np.float32)\n",
    "        self.portfolio_weights[0] = 1.0\n",
    "        self.done = False\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        end = self.current_step\n",
    "        start = end - self.window_size\n",
    "        return {\n",
    "            \"market_data\": self._market_data_numpy[start:end],\n",
    "            \"portfolio_weights\": self.portfolio_weights\n",
    "        }\n",
    "\n",
    "    def step(self, action):\n",
    "        self.prev_portfolio_value = self.portfolio_value\n",
    "        \n",
    "        # 1. Softmax (Action -> Weights)\n",
    "        action_clipped = np.clip(action, -20, 20)\n",
    "        exp_values = np.exp(action_clipped)\n",
    "        target_weights = exp_values / np.sum(exp_values)\n",
    "        \n",
    "        # 2. Kosten\n",
    "        turnover = np.sum(np.abs(target_weights[1:] - self.portfolio_weights[1:]))\n",
    "        costs = turnover * self.prev_portfolio_value * self.transaction_cost_pct\n",
    "        \n",
    "        # 3. Returns berechnen\n",
    "        current_data = self._market_data_numpy[self.current_step]\n",
    "        asset_returns = current_data[:, self.return_feature_idx]\n",
    "        \n",
    "        # Portfolio Rendite\n",
    "        weighted_return = np.sum(target_weights[1:] * asset_returns)\n",
    "        \n",
    "        val_after_cost = self.prev_portfolio_value - costs\n",
    "        self.portfolio_value = val_after_cost * (1 + weighted_return)\n",
    "        \n",
    "        # Bankrott Schutz\n",
    "        if self.portfolio_value < 1e-6:\n",
    "            self.portfolio_value = 1e-6\n",
    "            self.done = True\n",
    "            \n",
    "        # Reward: Log Return mit Scaling x100\n",
    "        reward_scale = 100.0 \n",
    "        log_return = np.log(self.portfolio_value / max(self.prev_portfolio_value, 1e-6))\n",
    "        reward = log_return * reward_scale\n",
    "        \n",
    "        if np.isnan(reward) or np.isinf(reward): reward = -10.0 \n",
    "        \n",
    "        self.portfolio_weights = target_weights\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step >= self.end_tick:\n",
    "            self.done = True\n",
    "            \n",
    "        info = {\n",
    "            \"portfolio_value\": self.portfolio_value,\n",
    "            \"turnover\": turnover,\n",
    "            \"weight_cash\": target_weights[0],\n",
    "            \"is_bankrupt\": self.portfolio_value <= 1e-5\n",
    "        }\n",
    "        \n",
    "        return self._get_observation(), reward, self.done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1763631787179,
     "user": {
      "displayName": "Christoph Nachname",
      "userId": "04640672557127032436"
     },
     "user_tz": -60
    },
    "id": "CX7qW-QLE1FF",
    "outputId": "fe7a18fd-cdfe-40c3-dc07-cf55b3ab315d"
   },
   "outputs": [],
   "source": [
    "# 5. Custom Policy & Callbacks (MIT DROPOUT & CLOUD TRIGGER)\n",
    "# ----------------------------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import wandb # Wichtig für den Upload\n",
    "\n",
    "# --- 1. Feature Extractor (LSTM mit Dropout) ---\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, extractor_type=\"LSTM\", hidden_size=128, rnn_dropout=0.0):\n",
    "        market_space = observation_space[\"market_data\"]\n",
    "        weights_space = observation_space[\"portfolio_weights\"]\n",
    "        \n",
    "        features_dim = hidden_size + weights_space.shape[0]\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        \n",
    "        # LSTM Definition\n",
    "        # WICHTIG: Dropout funktioniert bei PyTorch LSTMs nur, wenn num_layers >= 2\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=market_space.shape[1] * market_space.shape[2],\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,    # 2 Layer für Dropout-Effektivität\n",
    "            dropout=rnn_dropout if rnn_dropout > 0 else 0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "    def forward(self, observations):\n",
    "        market = observations[\"market_data\"]\n",
    "        weights = observations[\"portfolio_weights\"]\n",
    "        batch_size = market.shape[0]\n",
    "        \n",
    "        # Flatten\n",
    "        market_flat = market.reshape(batch_size, market.shape[1], -1)\n",
    "        \n",
    "        # LSTM Pass\n",
    "        _, (hidden, _) = self.lstm(market_flat)\n",
    "        \n",
    "        # Wir nehmen den letzten Hidden State\n",
    "        return torch.cat([hidden[-1], weights], dim=1)\n",
    "\n",
    "# --- 2. Callbacks ---\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\" Loggt Turnover, Cash und Bankrott-Rate. \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.buffer = {\"turnover\": [], \"cash\": [], \"bankrupt\": []}\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"turnover\" in info: self.buffer[\"turnover\"].append(info[\"turnover\"])\n",
    "            if \"weight_cash\" in info: self.buffer[\"cash\"].append(info[\"weight_cash\"])\n",
    "            if \"is_bankrupt\" in info: self.buffer[\"bankrupt\"].append(info[\"is_bankrupt\"])\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        if self.buffer[\"turnover\"]:\n",
    "            self.logger.record(\"live/avg_turnover\", np.mean(self.buffer[\"turnover\"]))\n",
    "            self.logger.record(\"live/avg_cash\", np.mean(self.buffer[\"cash\"]))\n",
    "            self.logger.record(\"live/bankrupt_rate\", np.mean(self.buffer[\"bankrupt\"]))\n",
    "        self.buffer = {\"turnover\": [], \"cash\": [], \"bankrupt\": []}\n",
    "\n",
    "# [NEU] Dieser Callback lädt das beste Modell sofort hoch, wenn es gefunden wird\n",
    "class TriggerWandbUploadCallback(BaseCallback):\n",
    "    def __init__(self, save_path, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Diese Methode wird vom EvalCallback aufgerufen\n",
    "        best_model_path = os.path.join(self.save_path, \"best_model.zip\")\n",
    "        \n",
    "        if os.path.exists(best_model_path) and wandb.run is not None:\n",
    "            try:\n",
    "                # Wir nutzen den Namen des aktuellen Runs + _BEST\n",
    "                artifact = wandb.Artifact(name=f\"{wandb.run.name}_BEST\", type=\"model\")\n",
    "                artifact.add_file(best_model_path)\n",
    "                wandb.log_artifact(artifact)\n",
    "                if self.verbose > 0:\n",
    "                    print(f\" [Cloud] ☁️ Neues Highscore-Modell hochgeladen!\")\n",
    "            except Exception as e:\n",
    "                print(f\" [Cloud] ❌ Upload fehlgeschlagen: {e}\")\n",
    "        return True\n",
    "\n",
    "class WandbCloudSaveCallback(BaseCallback):\n",
    "    \"\"\" Reguläres Backup alle X Schritte \"\"\"\n",
    "    def __init__(self, save_freq, save_path, name_prefix):\n",
    "        super().__init__(0)\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "        self.name_prefix = name_prefix\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "            path = os.path.join(self.save_path, f\"{self.name_prefix}_{self.num_timesteps}_steps\")\n",
    "            self.model.save(path)\n",
    "            if wandb.run is not None:\n",
    "                try:\n",
    "                    artifact = wandb.Artifact(name=f\"{self.name_prefix}_ckpt\", type=\"model\")\n",
    "                    artifact.add_file(f\"{path}.zip\")\n",
    "                    wandb.log_artifact(artifact)\n",
    "                except Exception as e:\n",
    "                    print(f\"Checkpoint Upload Fehler: {e}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "Gi7s3G4sE1FG",
    "outputId": "badef75b-935c-4328-95f8-66bf420731f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./data/wandb_logs/wandb/run-20251125_062430-wjhcgljh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cb-ml/PPO_Portfolio_SP500/runs/wjhcgljh' target=\"_blank\">PPO_LSTM_Transfer_a9fa390a</a></strong> to <a href='https://wandb.ai/cb-ml/PPO_Portfolio_SP500' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cb-ml/PPO_Portfolio_SP500' target=\"_blank\">https://wandb.ai/cb-ml/PPO_Portfolio_SP500</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cb-ml/PPO_Portfolio_SP500/runs/wjhcgljh' target=\"_blank\">https://wandb.ai/cb-ml/PPO_Portfolio_SP500/runs/wjhcgljh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 06:25:28.063875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764051928.080081    9600 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-25 06:25:28.081966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-25 06:25:28.082307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1764051928.085433    9600 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-25 06:25:28.086179: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764051928.099236    9598 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764051928.099549    9601 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1764051928.103356    9600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.103375    9600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.103378    9600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.103380    9600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764051928.104449    9599 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764051928.104551    9598 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1764051928.104922    9601 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-25 06:25:28.107396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1764051928.110164    9599 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764051928.122629    9598 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.122649    9598 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.122651    9598 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.122653    9598 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.123064    9601 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.123080    9601 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.123082    9601 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.123084    9601 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-25 06:25:28.126723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-25 06:25:28.127321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1764051928.127423    9599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.127439    9599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.127442    9599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764051928.127444    9599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-25 06:25:28.131721: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisiere NEUES PPO Modell...\n",
      "Using cuda device\n",
      "(Worker) Lade Daten: ./processed_data/features_cleaned.csv\n",
      "Return-Feature gefunden an Index 0: LogReturns\n",
      "Starte Training für 30000000 Schritte...\n",
      "Logging to runs/wjhcgljh/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.9/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f9e5122cc40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f9e451a5640>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=16384, episode_reward=26.78 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1.01e+03 |\n",
      "|    mean_reward     | 26.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      " [Cloud] ☁️ Neues Highscore-Modell hochgeladen!\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019833725 |\n",
      "|    avg_turnover    | 1.0375264    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -63.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 877          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 18           |\n",
      "|    total_timesteps | 16384        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=32768, episode_reward=26.76 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03546983 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -715       |\n",
      "|    explained_variance   | -0.00262   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.03       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019952357 |\n",
      "|    avg_turnover    | 1.0375829    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -65          |\n",
      "| time/              |              |\n",
      "|    fps             | 499          |\n",
      "|    iterations      | 2            |\n",
      "|    time_elapsed    | 65           |\n",
      "|    total_timesteps | 32768        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=49152, episode_reward=26.75 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045823686 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.628       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0572     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019318223 |\n",
      "|    avg_turnover    | 1.0370772    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -64.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 469          |\n",
      "|    iterations      | 3            |\n",
      "|    time_elapsed    | 104          |\n",
      "|    total_timesteps | 49152        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=65536, episode_reward=26.74 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0548044 |\n",
      "|    clip_fraction        | 0.328     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -715      |\n",
      "|    explained_variance   | 0.904     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.227     |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.0611   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020065708 |\n",
      "|    avg_turnover    | 1.037019     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -63.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 455          |\n",
      "|    iterations      | 4            |\n",
      "|    time_elapsed    | 143          |\n",
      "|    total_timesteps | 65536        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=81920, episode_reward=26.69 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0634122 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -715      |\n",
      "|    explained_variance   | 0.94      |\n",
      "|    learning_rate        | 0.000299  |\n",
      "|    loss                 | 0.13      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0561   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 0.976     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019786693 |\n",
      "|    avg_turnover    | 1.0362104    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -63.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 448          |\n",
      "|    iterations      | 5            |\n",
      "|    time_elapsed    | 182          |\n",
      "|    total_timesteps | 81920        |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=98304, episode_reward=26.70 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06709154 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -715       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.000299   |\n",
      "|    loss                 | 0.215      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.798      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001959844 |\n",
      "|    avg_turnover    | 1.0362635   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -63.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 444         |\n",
      "|    iterations      | 6           |\n",
      "|    time_elapsed    | 220         |\n",
      "|    total_timesteps | 98304       |\n",
      "------------------------------------\n",
      "Eval num_timesteps=114688, episode_reward=26.73 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.077886984 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.000299    |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0543     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.64        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019512571 |\n",
      "|    avg_turnover    | 1.0369861    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -63.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 442          |\n",
      "|    iterations      | 7            |\n",
      "|    time_elapsed    | 258          |\n",
      "|    total_timesteps | 114688       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=131072, episode_reward=26.69 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08808396 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -715       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.000299   |\n",
      "|    loss                 | 0.0452     |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.601      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020087948 |\n",
      "|    avg_turnover    | 1.0370616    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -63.3        |\n",
      "| time/              |              |\n",
      "|    fps             | 440          |\n",
      "|    iterations      | 8            |\n",
      "|    time_elapsed    | 297          |\n",
      "|    total_timesteps | 131072       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=147456, episode_reward=26.66 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11603393 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -715       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.000299   |\n",
      "|    loss                 | 0.032      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.053     |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.612      |\n",
      "----------------------------------------\n",
      "-----------------------------------\n",
      "| live/              |            |\n",
      "|    avg_cash        | 0.00200748 |\n",
      "|    avg_turnover    | 1.0357814  |\n",
      "|    bankrupt_rate   | 0          |\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 3.52e+03   |\n",
      "|    ep_rew_mean     | -63.1      |\n",
      "| time/              |            |\n",
      "|    fps             | 439        |\n",
      "|    iterations      | 9          |\n",
      "|    time_elapsed    | 335        |\n",
      "|    total_timesteps | 147456     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=163840, episode_reward=26.68 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090790406 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.000299    |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0616     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019609854 |\n",
      "|    avg_turnover    | 1.0364063    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 437          |\n",
      "|    iterations      | 10           |\n",
      "|    time_elapsed    | 374          |\n",
      "|    total_timesteps | 163840       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=180224, episode_reward=26.65 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098455764 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.000298    |\n",
      "|    loss                 | -0.0642     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0623     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019611767 |\n",
      "|    avg_turnover    | 1.0362322    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 436          |\n",
      "|    iterations      | 11           |\n",
      "|    time_elapsed    | 413          |\n",
      "|    total_timesteps | 180224       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=196608, episode_reward=26.63 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10920406 |\n",
      "|    clip_fraction        | 0.439      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -715       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.000298   |\n",
      "|    loss                 | -0.075     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0654    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019897018 |\n",
      "|    avg_turnover    | 1.035913     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 435          |\n",
      "|    iterations      | 12           |\n",
      "|    time_elapsed    | 451          |\n",
      "|    total_timesteps | 196608       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=212992, episode_reward=26.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.109514356 |\n",
      "|    clip_fraction        | 0.448       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.000298    |\n",
      "|    loss                 | -0.0882     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0704     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019640534 |\n",
      "|    avg_turnover    | 1.0358174    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 13           |\n",
      "|    time_elapsed    | 489          |\n",
      "|    total_timesteps | 212992       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=229376, episode_reward=26.64 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.102244206 |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -715        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.000298    |\n",
      "|    loss                 | -0.106      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0718     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019166886 |\n",
      "|    avg_turnover    | 1.036005     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 14           |\n",
      "|    time_elapsed    | 527          |\n",
      "|    total_timesteps | 229376       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=245760, episode_reward=26.64 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.01e+03    |\n",
      "|    mean_reward          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.121136606 |\n",
      "|    clip_fraction        | 0.481       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -714        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.000298    |\n",
      "|    loss                 | -0.0902     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0711     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019707538 |\n",
      "|    avg_turnover    | 1.0359578    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 15           |\n",
      "|    time_elapsed    | 565          |\n",
      "|    total_timesteps | 245760       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=262144, episode_reward=26.66 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24358712 |\n",
      "|    clip_fraction        | 0.497      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.000298   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0772    |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019831443 |\n",
      "|    avg_turnover    | 1.0362253    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62          |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 16           |\n",
      "|    time_elapsed    | 602          |\n",
      "|    total_timesteps | 262144       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=278528, episode_reward=26.71 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14158125 |\n",
      "|    clip_fraction        | 0.506      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.078     |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001940747 |\n",
      "|    avg_turnover    | 1.0355191   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -62.1       |\n",
      "| time/              |             |\n",
      "|    fps             | 434         |\n",
      "|    iterations      | 17          |\n",
      "|    time_elapsed    | 640         |\n",
      "|    total_timesteps | 278528      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=294912, episode_reward=26.63 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13716713 |\n",
      "|    clip_fraction        | 0.52       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.0962    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0768    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.13       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019437459 |\n",
      "|    avg_turnover    | 1.0364125    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62          |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 18           |\n",
      "|    time_elapsed    | 678          |\n",
      "|    total_timesteps | 294912       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=311296, episode_reward=26.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12930208 |\n",
      "|    clip_fraction        | 0.509      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.109     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0722    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019421673 |\n",
      "|    avg_turnover    | 1.0349956    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -62.1        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 19           |\n",
      "|    time_elapsed    | 715          |\n",
      "|    total_timesteps | 311296       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=327680, episode_reward=26.69 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22519055 |\n",
      "|    clip_fraction        | 0.535      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0764    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0018806071 |\n",
      "|    avg_turnover    | 1.0353304    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -61.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 20           |\n",
      "|    time_elapsed    | 753          |\n",
      "|    total_timesteps | 327680       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=344064, episode_reward=26.67 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14847837 |\n",
      "|    clip_fraction        | 0.555      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.119     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0756    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.146      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019267969 |\n",
      "|    avg_turnover    | 1.0351393    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -61.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 21           |\n",
      "|    time_elapsed    | 791          |\n",
      "|    total_timesteps | 344064       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=360448, episode_reward=26.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 360448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12792416 |\n",
      "|    clip_fraction        | 0.549      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0784    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019967896 |\n",
      "|    avg_turnover    | 1.0351928    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -61.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 434          |\n",
      "|    iterations      | 22           |\n",
      "|    time_elapsed    | 830          |\n",
      "|    total_timesteps | 360448       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=376832, episode_reward=26.69 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 376832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15177539 |\n",
      "|    clip_fraction        | 0.546      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.000296   |\n",
      "|    loss                 | -0.113     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0745    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019482204 |\n",
      "|    avg_turnover    | 1.0351427    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -61.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 433          |\n",
      "|    iterations      | 23           |\n",
      "|    time_elapsed    | 869          |\n",
      "|    total_timesteps | 376832       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=393216, episode_reward=26.61 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14128812 |\n",
      "|    clip_fraction        | 0.564      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000296   |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0812    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019720478 |\n",
      "|    avg_turnover    | 1.0344183    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -61.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 24           |\n",
      "|    time_elapsed    | 908          |\n",
      "|    total_timesteps | 393216       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=409600, episode_reward=26.51 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 409600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15406513 |\n",
      "|    clip_fraction        | 0.558      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000296   |\n",
      "|    loss                 | -0.128     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0781    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019825548 |\n",
      "|    avg_turnover    | 1.0346055    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -60.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 25           |\n",
      "|    time_elapsed    | 947          |\n",
      "|    total_timesteps | 409600       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=425984, episode_reward=26.51 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14951763 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.000296   |\n",
      "|    loss                 | -0.112     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0768    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0018976527 |\n",
      "|    avg_turnover    | 1.034605     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -60.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 26           |\n",
      "|    time_elapsed    | 986          |\n",
      "|    total_timesteps | 425984       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=442368, episode_reward=26.57 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17940359 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000296   |\n",
      "|    loss                 | -0.0813    |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0757    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019470437 |\n",
      "|    avg_turnover    | 1.034641     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -60.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 27           |\n",
      "|    time_elapsed    | 1024         |\n",
      "|    total_timesteps | 442368       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=458752, episode_reward=26.53 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 458752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1510368 |\n",
      "|    clip_fraction        | 0.586     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -714      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000296  |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0791   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001989171 |\n",
      "|    avg_turnover    | 1.0350507   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -60.3       |\n",
      "| time/              |             |\n",
      "|    fps             | 431         |\n",
      "|    iterations      | 28          |\n",
      "|    time_elapsed    | 1062        |\n",
      "|    total_timesteps | 458752      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=475136, episode_reward=26.47 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15898354 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000295   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0775    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019451514 |\n",
      "|    avg_turnover    | 1.034219     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -60          |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 29           |\n",
      "|    time_elapsed    | 1099         |\n",
      "|    total_timesteps | 475136       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=491520, episode_reward=26.47 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 491520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1735798 |\n",
      "|    clip_fraction        | 0.59      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -714      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000295  |\n",
      "|    loss                 | -0.118    |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -0.078    |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019766842 |\n",
      "|    avg_turnover    | 1.0342987    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -59.7        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 30           |\n",
      "|    time_elapsed    | 1137         |\n",
      "|    total_timesteps | 491520       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=507904, episode_reward=26.39 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15722398 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000295   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0784    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019434425 |\n",
      "|    avg_turnover    | 1.0344696    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -59.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 31           |\n",
      "|    time_elapsed    | 1175         |\n",
      "|    total_timesteps | 507904       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=524288, episode_reward=26.38 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.4      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 524288    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1681145 |\n",
      "|    clip_fraction        | 0.593     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -714      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000295  |\n",
      "|    loss                 | -0.121    |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.0772   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.109     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001922391 |\n",
      "|    avg_turnover    | 1.034446    |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -59.1       |\n",
      "| time/              |             |\n",
      "|    fps             | 432         |\n",
      "|    iterations      | 32          |\n",
      "|    time_elapsed    | 1212        |\n",
      "|    total_timesteps | 524288      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=540672, episode_reward=26.31 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 540672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18398994 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000295   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0748    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019318311 |\n",
      "|    avg_turnover    | 1.0348413    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -58.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 33           |\n",
      "|    time_elapsed    | 1250         |\n",
      "|    total_timesteps | 540672       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=557056, episode_reward=26.34 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 557056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17362753 |\n",
      "|    clip_fraction        | 0.609      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000295   |\n",
      "|    loss                 | -0.128     |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0791    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.122      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019326096 |\n",
      "|    avg_turnover    | 1.0347003    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -58.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 34           |\n",
      "|    time_elapsed    | 1288         |\n",
      "|    total_timesteps | 557056       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=573440, episode_reward=26.29 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18544692 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.137     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0772    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.099      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019291264 |\n",
      "|    avg_turnover    | 1.0354177    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -58.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 35           |\n",
      "|    time_elapsed    | 1326         |\n",
      "|    total_timesteps | 573440       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=589824, episode_reward=26.28 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17820513 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0769    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019408425 |\n",
      "|    avg_turnover    | 1.0341581    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -58.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 432          |\n",
      "|    iterations      | 36           |\n",
      "|    time_elapsed    | 1364         |\n",
      "|    total_timesteps | 589824       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=606208, episode_reward=26.23 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 606208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18959394 |\n",
      "|    clip_fraction        | 0.613      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0748    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019803054 |\n",
      "|    avg_turnover    | 1.0345516    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -58.1        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 37           |\n",
      "|    time_elapsed    | 1404         |\n",
      "|    total_timesteps | 606208       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=622592, episode_reward=26.17 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 622592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18188664 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0764    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0018961456 |\n",
      "|    avg_turnover    | 1.0346892    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -57.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 38           |\n",
      "|    time_elapsed    | 1443         |\n",
      "|    total_timesteps | 622592       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=638976, episode_reward=26.21 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 638976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18791409 |\n",
      "|    clip_fraction        | 0.627      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0786    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0018681043 |\n",
      "|    avg_turnover    | 1.0346061    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -57.7        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 39           |\n",
      "|    time_elapsed    | 1482         |\n",
      "|    total_timesteps | 638976       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=655360, episode_reward=26.16 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19308282 |\n",
      "|    clip_fraction        | 0.623      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000294   |\n",
      "|    loss                 | -0.107     |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0742    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001931255 |\n",
      "|    avg_turnover    | 1.0347902   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -57.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 40          |\n",
      "|    time_elapsed    | 1520        |\n",
      "|    total_timesteps | 655360      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=671744, episode_reward=26.13 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 671744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19161817 |\n",
      "|    clip_fraction        | 0.634      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000293   |\n",
      "|    loss                 | -0.135     |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0801    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0995     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001972297 |\n",
      "|    avg_turnover    | 1.034726    |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -57         |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 41          |\n",
      "|    time_elapsed    | 1558        |\n",
      "|    total_timesteps | 671744      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=688128, episode_reward=26.15 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 688128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20494443 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000293   |\n",
      "|    loss                 | -0.141     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0778    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0992     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019209615 |\n",
      "|    avg_turnover    | 1.0346272    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -56.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 42           |\n",
      "|    time_elapsed    | 1597         |\n",
      "|    total_timesteps | 688128       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=704512, episode_reward=26.08 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22616287 |\n",
      "|    clip_fraction        | 0.635      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000293   |\n",
      "|    loss                 | -0.129     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0778    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0985     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019619542 |\n",
      "|    avg_turnover    | 1.0338566    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -56.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 43           |\n",
      "|    time_elapsed    | 1635         |\n",
      "|    total_timesteps | 704512       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=720896, episode_reward=26.11 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20347951 |\n",
      "|    clip_fraction        | 0.638      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000293   |\n",
      "|    loss                 | -0.135     |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0765    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0975     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019177904 |\n",
      "|    avg_turnover    | 1.0344645    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -56.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 44           |\n",
      "|    time_elapsed    | 1673         |\n",
      "|    total_timesteps | 720896       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=737280, episode_reward=26.08 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26.1      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 737280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2224899 |\n",
      "|    clip_fraction        | 0.639     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -714      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000293  |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -0.0774   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.11      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019047499 |\n",
      "|    avg_turnover    | 1.0347452    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -56.1        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 45           |\n",
      "|    time_elapsed    | 1710         |\n",
      "|    total_timesteps | 737280       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=753664, episode_reward=25.97 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 753664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20905623 |\n",
      "|    clip_fraction        | 0.644      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -714       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000293   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0756    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019851893 |\n",
      "|    avg_turnover    | 1.0344338    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -56.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 46           |\n",
      "|    time_elapsed    | 1748         |\n",
      "|    total_timesteps | 753664       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=770048, episode_reward=26.01 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20750257 |\n",
      "|    clip_fraction        | 0.647      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000292   |\n",
      "|    loss                 | -0.12      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0776    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001984239 |\n",
      "|    avg_turnover    | 1.0345964   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -55.9       |\n",
      "| time/              |             |\n",
      "|    fps             | 431         |\n",
      "|    iterations      | 47          |\n",
      "|    time_elapsed    | 1786        |\n",
      "|    total_timesteps | 770048      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=786432, episode_reward=25.98 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 786432    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2333851 |\n",
      "|    clip_fraction        | 0.642     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000292  |\n",
      "|    loss                 | -0.134    |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -0.0767   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.0953    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.001976135 |\n",
      "|    avg_turnover    | 1.0345604   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -55.6       |\n",
      "| time/              |             |\n",
      "|    fps             | 431         |\n",
      "|    iterations      | 48          |\n",
      "|    time_elapsed    | 1823        |\n",
      "|    total_timesteps | 786432      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=802816, episode_reward=26.06 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21903901 |\n",
      "|    clip_fraction        | 0.642      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000292   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0745    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0954     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019741058 |\n",
      "|    avg_turnover    | 1.0345395    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -55.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 49           |\n",
      "|    time_elapsed    | 1863         |\n",
      "|    total_timesteps | 802816       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=819200, episode_reward=26.03 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 819200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21729606 |\n",
      "|    clip_fraction        | 0.653      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000292   |\n",
      "|    loss                 | -0.142     |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0779    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0977     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020045838 |\n",
      "|    avg_turnover    | 1.0340357    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -54.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 50           |\n",
      "|    time_elapsed    | 1902         |\n",
      "|    total_timesteps | 819200       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=835584, episode_reward=25.98 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 835584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20281222 |\n",
      "|    clip_fraction        | 0.653      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000292   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0766    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019488265 |\n",
      "|    avg_turnover    | 1.034258     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -54.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 51           |\n",
      "|    time_elapsed    | 1940         |\n",
      "|    total_timesteps | 835584       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=851968, episode_reward=26.05 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 851968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22366415 |\n",
      "|    clip_fraction        | 0.651      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000292   |\n",
      "|    loss                 | -0.12      |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0744    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019945458 |\n",
      "|    avg_turnover    | 1.0343356    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -54.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 52           |\n",
      "|    time_elapsed    | 1979         |\n",
      "|    total_timesteps | 851968       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=868352, episode_reward=26.01 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 868352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21969794 |\n",
      "|    clip_fraction        | 0.657      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0769    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.102      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020425962 |\n",
      "|    avg_turnover    | 1.033788     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -54.3        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 53           |\n",
      "|    time_elapsed    | 2017         |\n",
      "|    total_timesteps | 868352       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=884736, episode_reward=26.00 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23462504 |\n",
      "|    clip_fraction        | 0.658      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0785    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0951     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020017414 |\n",
      "|    avg_turnover    | 1.033847     |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -53.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 54           |\n",
      "|    time_elapsed    | 2056         |\n",
      "|    total_timesteps | 884736       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=901120, episode_reward=25.98 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 26        |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 901120    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2222858 |\n",
      "|    clip_fraction        | 0.659     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000291  |\n",
      "|    loss                 | -0.129    |\n",
      "|    n_updates            | 540       |\n",
      "|    policy_gradient_loss | -0.0789   |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 0.0941    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002039812 |\n",
      "|    avg_turnover    | 1.0337927   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -53.8       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 55          |\n",
      "|    time_elapsed    | 2094        |\n",
      "|    total_timesteps | 901120      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=917504, episode_reward=25.98 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22268614 |\n",
      "|    clip_fraction        | 0.661      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0781    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0935     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002046969 |\n",
      "|    avg_turnover    | 1.0339984   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -53.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 56          |\n",
      "|    time_elapsed    | 2131        |\n",
      "|    total_timesteps | 917504      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=933888, episode_reward=25.97 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 933888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22799623 |\n",
      "|    clip_fraction        | 0.666      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | -0.142     |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0789    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0966     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019926475 |\n",
      "|    avg_turnover    | 1.0345824    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -53.1        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 57           |\n",
      "|    time_elapsed    | 2169         |\n",
      "|    total_timesteps | 933888       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=950272, episode_reward=25.99 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 950272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24128276 |\n",
      "|    clip_fraction        | 0.666      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.0761    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.132      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020519004 |\n",
      "|    avg_turnover    | 1.0345179    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -52.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 58           |\n",
      "|    time_elapsed    | 2207         |\n",
      "|    total_timesteps | 950272       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=966656, episode_reward=25.96 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 966656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24916042 |\n",
      "|    clip_fraction        | 0.667      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0782    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020494917 |\n",
      "|    avg_turnover    | 1.0343822    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -52.1        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 59           |\n",
      "|    time_elapsed    | 2245         |\n",
      "|    total_timesteps | 966656       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=983040, episode_reward=25.98 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24476457 |\n",
      "|    clip_fraction        | 0.666      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0759    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0977     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002006776 |\n",
      "|    avg_turnover    | 1.0345796   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -51.7       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 60          |\n",
      "|    time_elapsed    | 2283        |\n",
      "|    total_timesteps | 983040      |\n",
      "------------------------------------\n",
      "Eval num_timesteps=999424, episode_reward=25.95 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 999424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22763717 |\n",
      "|    clip_fraction        | 0.667      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.137     |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.077     |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.091      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020036867 |\n",
      "|    avg_turnover    | 1.0335674    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -51.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 61           |\n",
      "|    time_elapsed    | 2320         |\n",
      "|    total_timesteps | 999424       |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1015808, episode_reward=25.92 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1015808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23882765 |\n",
      "|    clip_fraction        | 0.669      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.135     |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.0761    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0971     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020476913 |\n",
      "|    avg_turnover    | 1.0350742    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -51          |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 62           |\n",
      "|    time_elapsed    | 2358         |\n",
      "|    total_timesteps | 1015808      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1032192, episode_reward=25.88 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1032192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24317583 |\n",
      "|    clip_fraction        | 0.67       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0766    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0989     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019382597 |\n",
      "|    avg_turnover    | 1.0349264    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -50.7        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 63           |\n",
      "|    time_elapsed    | 2396         |\n",
      "|    total_timesteps | 1032192      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1048576, episode_reward=25.88 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1048576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22764134 |\n",
      "|    clip_fraction        | 0.665      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.00029    |\n",
      "|    loss                 | -0.121     |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0737    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.114      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019915754 |\n",
      "|    avg_turnover    | 1.0343986    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -50.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 64           |\n",
      "|    time_elapsed    | 2434         |\n",
      "|    total_timesteps | 1048576      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1064960, episode_reward=25.72 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1064960   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2306803 |\n",
      "|    clip_fraction        | 0.672     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.00029   |\n",
      "|    loss                 | -0.134    |\n",
      "|    n_updates            | 640       |\n",
      "|    policy_gradient_loss | -0.078    |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 0.0985    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020451332 |\n",
      "|    avg_turnover    | 1.0344547    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -50          |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 65           |\n",
      "|    time_elapsed    | 2471         |\n",
      "|    total_timesteps | 1064960      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1081344, episode_reward=25.72 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1081344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23604971 |\n",
      "|    clip_fraction        | 0.67       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000289   |\n",
      "|    loss                 | -0.128     |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0748    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020201742 |\n",
      "|    avg_turnover    | 1.0336083    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -49.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 66           |\n",
      "|    time_elapsed    | 2509         |\n",
      "|    total_timesteps | 1081344      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1097728, episode_reward=25.75 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24347584 |\n",
      "|    clip_fraction        | 0.675      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000289   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0753    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002064414 |\n",
      "|    avg_turnover    | 1.0338572   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -49.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 67          |\n",
      "|    time_elapsed    | 2547        |\n",
      "|    total_timesteps | 1097728     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1114112, episode_reward=25.54 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1114112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24333198 |\n",
      "|    clip_fraction        | 0.676      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000289   |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0764    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0981     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020553286 |\n",
      "|    avg_turnover    | 1.0338447    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -48.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 68           |\n",
      "|    time_elapsed    | 2585         |\n",
      "|    total_timesteps | 1114112      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1130496, episode_reward=25.50 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.5      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1130496   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2499621 |\n",
      "|    clip_fraction        | 0.676     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000289  |\n",
      "|    loss                 | -0.143    |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | -0.0764   |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 0.0925    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019343225 |\n",
      "|    avg_turnover    | 1.0343328    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -48.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 69           |\n",
      "|    time_elapsed    | 2623         |\n",
      "|    total_timesteps | 1130496      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1146880, episode_reward=25.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1146880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23584908 |\n",
      "|    clip_fraction        | 0.675      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000289   |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0756    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020022984 |\n",
      "|    avg_turnover    | 1.0342307    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -48.3        |\n",
      "| time/              |              |\n",
      "|    fps             | 431          |\n",
      "|    iterations      | 70           |\n",
      "|    time_elapsed    | 2660         |\n",
      "|    total_timesteps | 1146880      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1163264, episode_reward=25.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1163264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26944232 |\n",
      "|    clip_fraction        | 0.685      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000289   |\n",
      "|    loss                 | -0.133     |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0773    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0974     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002040214 |\n",
      "|    avg_turnover    | 1.0342389   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -48         |\n",
      "| time/              |             |\n",
      "|    fps             | 431         |\n",
      "|    iterations      | 71          |\n",
      "|    time_elapsed    | 2698        |\n",
      "|    total_timesteps | 1163264     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1179648, episode_reward=25.66 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 1.01e+03 |\n",
      "|    mean_reward          | 25.7     |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 1179648  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.261164 |\n",
      "|    clip_fraction        | 0.683    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -713     |\n",
      "|    explained_variance   | 0.998    |\n",
      "|    learning_rate        | 0.000288 |\n",
      "|    loss                 | -0.136   |\n",
      "|    n_updates            | 710      |\n",
      "|    policy_gradient_loss | -0.0778  |\n",
      "|    std                  | 0.996    |\n",
      "|    value_loss           | 0.0923   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002079627 |\n",
      "|    avg_turnover    | 1.034217    |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -47.4       |\n",
      "| time/              |             |\n",
      "|    fps             | 431         |\n",
      "|    iterations      | 72          |\n",
      "|    time_elapsed    | 2736        |\n",
      "|    total_timesteps | 1179648     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1196032, episode_reward=25.91 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1196032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25527537 |\n",
      "|    clip_fraction        | 0.681      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000288   |\n",
      "|    loss                 | -0.13      |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0765    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020610807 |\n",
      "|    avg_turnover    | 1.0336328    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -46.8        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 73           |\n",
      "|    time_elapsed    | 2775         |\n",
      "|    total_timesteps | 1196032      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1212416, episode_reward=25.64 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1212416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25951293 |\n",
      "|    clip_fraction        | 0.684      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000288   |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.0761    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020919165 |\n",
      "|    avg_turnover    | 1.0340314    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -46.4        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 74           |\n",
      "|    time_elapsed    | 2815         |\n",
      "|    total_timesteps | 1212416      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1228800, episode_reward=25.86 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1228800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26589096 |\n",
      "|    clip_fraction        | 0.68       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000288   |\n",
      "|    loss                 | -0.134     |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0739    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.0996     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020407748 |\n",
      "|    avg_turnover    | 1.0345473    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -46.3        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 75           |\n",
      "|    time_elapsed    | 2854         |\n",
      "|    total_timesteps | 1228800      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1245184, episode_reward=25.92 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1245184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26679432 |\n",
      "|    clip_fraction        | 0.681      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000288   |\n",
      "|    loss                 | -0.122     |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0732    |\n",
      "|    std                  | 0.996      |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002046478 |\n",
      "|    avg_turnover    | 1.0342737   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -45.9       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 76          |\n",
      "|    time_elapsed    | 2893        |\n",
      "|    total_timesteps | 1245184     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1261568, episode_reward=26.01 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1261568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25499368 |\n",
      "|    clip_fraction        | 0.682      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000288   |\n",
      "|    loss                 | -0.126     |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0762    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002078543 |\n",
      "|    avg_turnover    | 1.0340487   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -45.7       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 77          |\n",
      "|    time_elapsed    | 2931        |\n",
      "|    total_timesteps | 1261568     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1277952, episode_reward=26.18 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 26.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1277952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26959345 |\n",
      "|    clip_fraction        | 0.685      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000287   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0754    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.103      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002045887 |\n",
      "|    avg_turnover    | 1.0344715   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -45.3       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 78          |\n",
      "|    time_elapsed    | 2969        |\n",
      "|    total_timesteps | 1277952     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1294336, episode_reward=25.92 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.9      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1294336   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2777987 |\n",
      "|    clip_fraction        | 0.685     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.000287  |\n",
      "|    loss                 | -0.11     |\n",
      "|    n_updates            | 780       |\n",
      "|    policy_gradient_loss | -0.0716   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.113     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002115245 |\n",
      "|    avg_turnover    | 1.0345747   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -45         |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 79          |\n",
      "|    time_elapsed    | 3007        |\n",
      "|    total_timesteps | 1294336     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1310720, episode_reward=25.76 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1310720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25642592 |\n",
      "|    clip_fraction        | 0.686      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000287   |\n",
      "|    loss                 | -0.137     |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.0753    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.09       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020750442 |\n",
      "|    avg_turnover    | 1.0342978    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -44.7        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 80           |\n",
      "|    time_elapsed    | 3044         |\n",
      "|    total_timesteps | 1310720      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1327104, episode_reward=25.77 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1327104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27639765 |\n",
      "|    clip_fraction        | 0.689      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000287   |\n",
      "|    loss                 | -0.132     |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0785    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0941     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019793066 |\n",
      "|    avg_turnover    | 1.0347568    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -44.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 81           |\n",
      "|    time_elapsed    | 3082         |\n",
      "|    total_timesteps | 1327104      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1343488, episode_reward=25.66 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1343488   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2730658 |\n",
      "|    clip_fraction        | 0.692     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000287  |\n",
      "|    loss                 | -0.124    |\n",
      "|    n_updates            | 810       |\n",
      "|    policy_gradient_loss | -0.078    |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.104     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002012563 |\n",
      "|    avg_turnover    | 1.0341799   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -44.2       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 82          |\n",
      "|    time_elapsed    | 3120        |\n",
      "|    total_timesteps | 1343488     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1359872, episode_reward=25.71 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1359872   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2791054 |\n",
      "|    clip_fraction        | 0.689     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000287  |\n",
      "|    loss                 | -0.121    |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -0.0772   |\n",
      "|    std                  | 0.996     |\n",
      "|    value_loss           | 0.108     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019435314 |\n",
      "|    avg_turnover    | 1.0343183    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -43.6        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 83           |\n",
      "|    time_elapsed    | 3158         |\n",
      "|    total_timesteps | 1359872      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1376256, episode_reward=25.67 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1376256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25619328 |\n",
      "|    clip_fraction        | 0.692      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000286   |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.0767    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002024908 |\n",
      "|    avg_turnover    | 1.0351465   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -43.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 84          |\n",
      "|    time_elapsed    | 3195        |\n",
      "|    total_timesteps | 1376256     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1392640, episode_reward=25.58 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1392640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29132548 |\n",
      "|    clip_fraction        | 0.696      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000286   |\n",
      "|    loss                 | -0.149     |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.075     |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0934     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020820752 |\n",
      "|    avg_turnover    | 1.0352485    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -43.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 85           |\n",
      "|    time_elapsed    | 3235         |\n",
      "|    total_timesteps | 1392640      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1409024, episode_reward=25.55 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.5       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1409024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27164653 |\n",
      "|    clip_fraction        | 0.691      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000286   |\n",
      "|    loss                 | -0.141     |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.0771    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0875     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020000164 |\n",
      "|    avg_turnover    | 1.0350752    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -42.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 86           |\n",
      "|    time_elapsed    | 3273         |\n",
      "|    total_timesteps | 1409024      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1425408, episode_reward=25.58 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1425408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27361313 |\n",
      "|    clip_fraction        | 0.694      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000286   |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0783    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.0953     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| live/              |             |\n",
      "|    avg_cash        | 0.002021893 |\n",
      "|    avg_turnover    | 1.0351703   |\n",
      "|    bankrupt_rate   | 0           |\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 3.52e+03    |\n",
      "|    ep_rew_mean     | -42.5       |\n",
      "| time/              |             |\n",
      "|    fps             | 430         |\n",
      "|    iterations      | 87          |\n",
      "|    time_elapsed    | 3312        |\n",
      "|    total_timesteps | 1425408     |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1441792, episode_reward=25.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.01e+03   |\n",
      "|    mean_reward          | 25.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1441792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26591837 |\n",
      "|    clip_fraction        | 0.694      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -713       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.000286   |\n",
      "|    loss                 | -0.139     |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0781    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 0.096      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0019684501 |\n",
      "|    avg_turnover    | 1.0346732    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -42.2        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 88           |\n",
      "|    time_elapsed    | 3351         |\n",
      "|    total_timesteps | 1441792      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1458176, episode_reward=25.71 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.7      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1458176   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2751655 |\n",
      "|    clip_fraction        | 0.693     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000286  |\n",
      "|    loss                 | -0.12     |\n",
      "|    n_updates            | 880       |\n",
      "|    policy_gradient_loss | -0.0763   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.121     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020351112 |\n",
      "|    avg_turnover    | 1.0355275    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -41.9        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 89           |\n",
      "|    time_elapsed    | 3390         |\n",
      "|    total_timesteps | 1458176      |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1474560, episode_reward=25.62 +/- 0.00\n",
      "Episode length: 1006.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.01e+03  |\n",
      "|    mean_reward          | 25.6      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1474560   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2762356 |\n",
      "|    clip_fraction        | 0.691     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -713      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.000285  |\n",
      "|    loss                 | -0.123    |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | -0.0756   |\n",
      "|    std                  | 0.997     |\n",
      "|    value_loss           | 0.102     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| live/              |              |\n",
      "|    avg_cash        | 0.0020117373 |\n",
      "|    avg_turnover    | 1.0349044    |\n",
      "|    bankrupt_rate   | 0            |\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 3.52e+03     |\n",
      "|    ep_rew_mean     | -41.7        |\n",
      "| time/              |              |\n",
      "|    fps             | 430          |\n",
      "|    iterations      | 90           |\n",
      "|    time_elapsed    | 3428         |\n",
      "|    total_timesteps | 1474560      |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Training Loop (MIT W&B LOAD & SAVE)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return progress_remaining * initial_value\n",
    "    return func\n",
    "\n",
    "def train(config):\n",
    "    # W&B Init\n",
    "    run = wandb.init(\n",
    "        project=config[\"project_name\"],\n",
    "        config=config,\n",
    "        name=config[\"run_name\"],\n",
    "        sync_tensorboard=True,\n",
    "        monitor_gym=True,\n",
    "        dir=config[\"wandb_log_dir\"]\n",
    "    )\n",
    "    run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "    cfg = wandb.config\n",
    "    \n",
    "    # Pfade & Env\n",
    "    data_cfg = {\"feature_csv_path\": cfg.feature_csv_path}\n",
    "    env_cfg = {\n",
    "        \"initial_balance\": cfg.initial_balance,\n",
    "        \"window_size\": cfg.window_size,\n",
    "        \"transaction_cost_pct\": cfg.transaction_cost_pct\n",
    "    }\n",
    "    \n",
    "    num_cpu = 4 \n",
    "    train_env = SubprocVecEnv([\n",
    "        partial(create_env, data_cfg, env_cfg, cfg.train_start_date, cfg.train_end_date)\n",
    "        for _ in range(num_cpu)\n",
    "    ])\n",
    "    \n",
    "    callbacks = [TensorboardCallback()]\n",
    "    \n",
    "    # --- MODEL DEFINITION (Architektur) ---\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=CustomCombinedExtractor,\n",
    "        features_extractor_kwargs=dict(\n",
    "            hidden_size=cfg.extractor_hidden_size,\n",
    "            rnn_dropout=cfg.get(\"extractor_rnn_dropout\", 0.0)\n",
    "        ),\n",
    "        net_arch=dict(pi=cfg.policy_pi_arch, vf=cfg.policy_vf_arch)\n",
    "    )\n",
    "\n",
    "    # --- LADE-LOGIK (CLOUD RESTORE) ---\n",
    "    model = None\n",
    "    \n",
    "    if cfg.get(\"load_artifact_path\"):\n",
    "        print(f\"--- Versuche Modell aus W&B Cloud zu laden: {cfg.load_artifact_path} ---\")\n",
    "        try:\n",
    "            # 1. Artifact herunterladen\n",
    "            artifact = run.use_artifact(cfg.load_artifact_path, type='model')\n",
    "            artifact_dir = artifact.download()\n",
    "            print(f\"Artifact heruntergeladen nach: {artifact_dir}\")\n",
    "            \n",
    "            # 2. Modell laden (Wir suchen nach .zip Dateien im Ordner)\n",
    "            model_file = next((f for f in os.listdir(artifact_dir) if f.endswith(\".zip\")), None)\n",
    "            if model_file:\n",
    "                full_path = os.path.join(artifact_dir, model_file)\n",
    "                \n",
    "                # Parameter für Fine-Tuning (Lernrate etc.) überschreiben wir\n",
    "                custom_objects = {\n",
    "                    \"learning_rate\": linear_schedule(cfg.learning_rate),\n",
    "                    \"ent_coef\": cfg.ent_coef,\n",
    "                    \"clip_range\": cfg.clip_range\n",
    "                }\n",
    "                \n",
    "                model = PPO.load(\n",
    "                    full_path, \n",
    "                    env=train_env, \n",
    "                    custom_objects=custom_objects,\n",
    "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                    print_system_info=True\n",
    "                )\n",
    "                print(f\"✅ ERFOLG: Modell '{model_file}' geladen und bereit für Training!\")\n",
    "            else:\n",
    "                print(\"❌ FEHLER: Keine .zip Datei im Artifact gefunden.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ CRASH beim Laden aus Cloud: {e}\")\n",
    "            print(\"Starte stattdessen neues Modell...\")\n",
    "            model = None\n",
    "\n",
    "    # Fallback: Neues Modell\n",
    "    if model is None:\n",
    "        print(\"Initialisiere NEUES PPO Modell...\")\n",
    "        model = PPO(\n",
    "            \"MultiInputPolicy\",\n",
    "            train_env,\n",
    "            n_steps=cfg.n_steps,\n",
    "            batch_size=cfg.batch_size,\n",
    "            learning_rate=linear_schedule(cfg.learning_rate), \n",
    "            ent_coef=cfg.ent_coef,\n",
    "            clip_range=cfg.clip_range,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log=f\"runs/{run.id}\",\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    # --- CALLBACKS SETUP ---\n",
    "    if cfg.save_model:\n",
    "        save_path = os.path.join(cfg.model_save_dir, cfg.run_name)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # A) Der \"Trigger\", der bei neuem Best-Model sofort hochlädt\n",
    "        upload_trigger = TriggerWandbUploadCallback(save_path, verbose=1)\n",
    "        \n",
    "        # B) Der EvalCallback, der prüft und lokal speichert\n",
    "        eval_callback = EvalCallback(\n",
    "            DummyVecEnv([lambda: create_env(data_cfg, env_cfg, cfg.eval_start_date, cfg.eval_end_date)]),\n",
    "            best_model_save_path=save_path,\n",
    "            log_path=save_path,\n",
    "            eval_freq=cfg.n_steps,\n",
    "            deterministic=True,\n",
    "            verbose=1,\n",
    "            callback_on_new_best=upload_trigger # <--- HIER VERKNÜPFEN WIR SIE\n",
    "        )\n",
    "        callbacks.append(eval_callback)\n",
    "        \n",
    "        # C) Der Regular Checkpoint Saver (alle 100k Steps)\n",
    "        callbacks.append(WandbCloudSaveCallback(100_000, save_path, cfg.run_name))\n",
    "\n",
    "    # --- START ---\n",
    "    try:\n",
    "        print(f\"Starte Training für {cfg.total_timesteps} Schritte...\")\n",
    "        model.learn(total_timesteps=cfg.total_timesteps, callback=CallbackList(callbacks))\n",
    "        print(\"Training beendet.\")\n",
    "    finally:\n",
    "        train_env.close()\n",
    "        run.finish()\n",
    "\n",
    "def create_env(data_config, env_config, start, end):\n",
    "    env = PortfolioEnv(data_config, env_config, start, end)\n",
    "    return Monitor(env)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'config' in globals():\n",
    "        train(config)\n",
    "    else:\n",
    "        print(\"Bitte Config-Zelle ausführen!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1s0Cped5MHj8Lnef6mijNTjLULzbwdDRE",
     "timestamp": 1762620994425
    },
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/christophbieritz/ppo-stable-baseline-v2.e0d09903-048c-4ed6-b4b2-0352c7265933.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20251108/auto/storage/goog4_request&X-Goog-Date=20251108T060700Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=651bd69ccf890d4aef35ff5f0ed5871631ce648bcadfcd5bfeb3367cf72adf30fffbf3451176c7bc7c23603a2477953ab955d70842f359b891dc50c6f2d9174d578b4c53c0af0c2506d49e830fa3ec5141a2bcd6ed6c72faf1768ad5f10745b2556b303c5f15f80334e18555812e70a5f44cdc3cfb4a284d8380daf3ef38a1884a819b1fe031b4b2209aeccc1d0ee02265eb332a1241d9a9b5564560fd12ed3159f0e7b1181a903c8bebc16062b41e85b67e61b926e73d8e426700c723d319965d53778182a6f215f6a259dde0ddc642cd43358577b99040cf5dbc0c08f175f4d2d004df045cf21ca8fb4705a4e266ef0dda5c42ddbf613a2fb4a62d46714e29",
     "timestamp": 1762582068257
    }
   ]
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8673648,
     "sourceId": 13644596,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
